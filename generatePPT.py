"""æ ¹æ® JSON æè¿°å¤åˆ¶æ¨¡æ¿ã€å¡«å……æ–‡æœ¬/å›¾ç‰‡å¹¶ç”Ÿæˆæœ€ç»ˆ PPTã€‚"""

import argparse
import json
import re
import tempfile
import zipfile
from pathlib import Path

from PIL import Image
from lxml import etree
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE
from pptx.util import Pt

from archive.generatePPT_template import build_from_json


SUFFIXES = ("åŒº", "æ¡†", "æ ")
PLACEHOLDER_KEYWORDS = ("æ–‡å­—å†…å®¹", "å­—å¹•", "æ ‡é¢˜åç§°", "å†…å®¹å†…å®¹")
SUBTITLE_TEXTS = (
    "å­—å¹•18ptï¼Œç™½è‰²å­—ä½“æ·±è‰²æè¾¹ï¼Œæ‚¬æµ®é˜´å½±ã€‚ç¡®ä¿åœ¨ä»»ä½•åº•è‰²ä¸Šéƒ½èƒ½æ˜ç¡®æ˜¾ç¤º",
)
IGNORE_KEYWORDS = ("èƒŒæ™¯", "çŸ©å½¢", "åœ†è§’", "æ¤­åœ†", "å½¢çŠ¶", "å›¾å½¢", "é®ç½©", "åº•è‰²")
EXPANDABLE_KEYWORDS = ("æ ‡é¢˜", "åç§°", "è¯¾é¢˜", "æ ç›®")
EMU_PER_PT = 12700
H_PADDING = 20000  # çº¦ 1.5 æ¯«ç±³
MANUAL_NAME_MAP = {
    "ç›®å½•å†…å®¹åŒº1": ["æ–‡æœ¬æ¡† 9"],
    "ç›®å½•å†…å®¹åŒº2": ["æ–‡æœ¬æ¡† 14"],
    "ç›®å½•å†…å®¹åŒº3": ["æ–‡æœ¬æ¡† 17"],
    "ç›®å½•å†…å®¹åŒº4": ["æ–‡æœ¬æ¡† 20"],
    # å¸¸è§å­—å¹•æ¡†
    "å­—å¹•": ["æ–‡æœ¬æ¡† 10", "æ–‡æœ¬æ¡† 32", "æ–‡æœ¬æ¡† 36", "æ–‡æœ¬æ¡† 58", "æ–‡æœ¬æ¡† 121"],
}
NSMAP = {
    "p": "http://schemas.openxmlformats.org/presentationml/2006/main",
    "a": "http://schemas.openxmlformats.org/drawingml/2006/main",
}
SLIDE_RE = re.compile(r"ppt/slides/slide(\d+)\.xml")


def _iter_shapes(shapes):
    """é€’å½’éå†å¹»ç¯ç‰‡ï¼ŒåŒ…å«ç»„åˆå†…éƒ¨çš„å½¢çŠ¶ã€‚"""
    for shape in shapes:
        if shape.shape_type == MSO_SHAPE_TYPE.GROUP:
            yield from _iter_shapes(shape.shapes)
        else:
            yield shape


def _iter_shapes_with_path(shapes, parent_path=None):
    """é€’å½’éå†å¹»ç¯ç‰‡ï¼Œè¿”å› (shape, è·¯å¾„)ã€‚"""
    for idx, shape in enumerate(shapes, start=1):
        name = (shape.name or "").strip() or f"å…ƒç´ {idx}"
        path = (*parent_path, name) if parent_path else (name,)
        yield shape, path
        if shape.shape_type == MSO_SHAPE_TYPE.GROUP:
            yield from _iter_shapes_with_path(shape.shapes, path)


def _is_picture_shape(shape):
    """åˆ¤æ–­å½¢çŠ¶æ˜¯å¦å……å½“å›¾ç‰‡å ä½ç¬¦ã€‚"""
    name = shape.name or ""
    if "å›¾ç‰‡åŒº" in name or name.startswith("å›¾ç‰‡"):
        return True
    if shape.shape_type == MSO_SHAPE_TYPE.PICTURE:
        return True
    if shape.is_placeholder:
        try:
            return shape.placeholder_format.type == 18
        except ValueError:
            return False
    return False


def _is_placeholder_shape(shape):
    """è¯†åˆ«æ™®é€šæ–‡æœ¬å ä½ç¬¦ï¼Œç”¨äºç›®å½•â€œæ–‡å­—æ–‡å­—â€è¿™ç±»å†…å®¹ã€‚"""
    if not shape.has_text_frame:
        return False
    text = (shape.text_frame.text or "").strip()
    name = shape.name or ""
    if name.startswith("æ–‡æœ¬æ¡†"):
        return True
    return any(keyword in text for keyword in PLACEHOLDER_KEYWORDS)


def _detect_prefix(slide):
    counter = {}
    for _, path in _iter_shapes_with_path(slide.shapes):
        for segment in path:
            prefix = _extract_prefix(segment)
            if prefix:
                counter[prefix] = counter.get(prefix, 0) + 1
    if not counter:
        return None
    return max(counter.items(), key=lambda item: item[1])[0]


def _extract_prefix(name):
    if "_" not in name:
        return None
    prefix = name.split("_", 1)[0]
    return prefix if "é¡µ" in prefix else None


def _normalize_path(path, page_prefix):
    start_idx = 0
    if page_prefix:
        start_idx = -1
        for idx, segment in enumerate(path):
            if page_prefix in segment:
                start_idx = idx
                break
        if start_idx == -1:
            return []
    trimmed = []
    for segment in path[start_idx:]:
        seg = _clean_segment(segment, page_prefix)
        if not seg:
            continue
        trimmed.append(seg)
    return trimmed


def _clean_segment(segment, page_prefix):
    seg = segment.strip()
    if not seg:
        return ""
    if page_prefix and seg.startswith(page_prefix + "_"):
        seg = seg[len(page_prefix) + 1 :]
    for keyword in IGNORE_KEYWORDS:
        if keyword in seg:
            return ""
    return seg


def _flatten_content(content):
    mapping = {}

    def walk(node, path):
        if isinstance(node, dict):
            for key, value in node.items():
                walk(value, path + (key,))
        else:
            mapping[path] = node

    walk(content or {}, tuple())
    return mapping


def _shape_aliases(name):
    """ä¸ºå½¢çŠ¶åç§°ç”Ÿæˆå¤šç§åˆ«åï¼Œæå‡åŒ¹é…æˆåŠŸç‡ã€‚"""
    aliases = set()
    clean = name.strip()
    if not clean:
        return aliases

    aliases.update({clean, clean.replace(" ", "")})

    def _add_parts(separator):
        if separator in clean:
            parts = [p for p in clean.split(separator) if p]
            for part in parts:
                aliases.add(part)
                aliases.add(part.replace(" ", ""))

    _add_parts("_")
    _add_parts("-")

    extra = set()
    for alias in aliases:
        for suf in SUFFIXES:
            if alias.endswith(suf):
                trimmed = alias[: -len(suf)]
                extra.add(trimmed)
                extra.add(trimmed.replace(" ", ""))
    aliases.update(extra)
    return aliases


def _candidate_keys(key):
    """ç»™å®š JSON ä¸­çš„é”®åï¼Œç”Ÿæˆè‹¥å¹²åŒ¹é…å€™é€‰ã€‚"""
    key = key.strip()
    variants = [key, key.replace(" ", "")]
    for suf in SUFFIXES:
        if key.endswith(suf):
            variants.append(key[: -len(suf)])
            variants.append(key[: -len(suf)].replace(" ", ""))
    seen = set()
    result = []
    for variant in variants:
        if variant and variant not in seen:
            result.append(variant)
            seen.add(variant)
    return result


def _set_shape_text(shape, text):
    """å¡«å……æ–‡æœ¬æ—¶å°½é‡ä¿æŒåŸæœ‰æ ¼å¼ã€‚"""
    if not shape.has_text_frame:
        return

    text = "" if text is None else str(text)
    lines = text.split("\n")
    tf = shape.text_frame

    if not tf.paragraphs:
        tf.add_paragraph()

    for idx, line in enumerate(lines):
        if idx < len(tf.paragraphs):
            para = tf.paragraphs[idx]
        else:
            para = tf.add_paragraph()

        if para.runs:
            para.runs[0].text = line
            for run in para.runs[1:]:
                run.text = ""
        else:
            para.text = line

    # æ¸…ç†å¤šä½™æ®µè½
    for idx in range(len(lines), len(tf.paragraphs)):
        for run in tf.paragraphs[idx].runs:
            run.text = ""

    tf.word_wrap = True


def _safe_remove_shape(shape):
    element_parent = shape.element.getparent()
    if element_parent is not None:
        element_parent.remove(shape.element)


def _replace_picture(slide, shape, image_path):
    """å°†å›¾ç‰‡å ä½ç¬¦æ›¿æ¢ä¸ºæœ¬åœ°å›¾ç‰‡ï¼Œä¿æŒä½ç½®å¤§å°æ¯”ç‡ã€‚"""
    if not image_path:
        _safe_remove_shape(shape)
        return

    image_path = Path(image_path)
    if not image_path.is_file():
        print(f"âš ï¸  å›¾ç‰‡æ–‡ä»¶ä¸å¯ç”¨ï¼š{image_path}")
        _safe_remove_shape(shape)
        return

    left, top, width, height = shape.left, shape.top, shape.width, shape.height
    name = shape.name

    with Image.open(image_path) as img:
        img_w, img_h = img.size

    img_ratio = img_w / img_h
    box_ratio = width / height
    if img_ratio > box_ratio:
        new_width = width
        new_height = width / img_ratio
    else:
        new_height = height
        new_width = height * img_ratio

    new_left = int(left + (width - new_width) / 2)
    new_top = int(top + (height - new_height) / 2)
    new_width = int(new_width)
    new_height = int(new_height)

    parent_shapes = getattr(shape, "_parent", None)
    _safe_remove_shape(shape)
    if parent_shapes is None:
        # æŸäº›å ä½å±äºç»„åˆä½† XML å·²è¢«å‰¥ç¦»ï¼Œæ­¤æ—¶æ— æ³•å®‰å…¨ç§»é™¤ï¼Œç›´æ¥ä¿ç•™åŸçˆ¶å±‚
        parent_shapes = slide.shapes

    if parent_shapes is None or not hasattr(parent_shapes, "add_picture"):
        parent_shapes = slide.shapes

    new_pic = parent_shapes.add_picture(
        str(image_path), new_left, new_top, width=new_width, height=new_height
    )
    new_pic.name = name


def _fill_slide(slide, page_content, slide_width):
    """æ ¹æ® JSON å†…å®¹æŠŠæ–‡æœ¬å’Œå›¾ç‰‡å†™å…¥å¯¹åº”åŒºåŸŸã€‚"""
    prefix = _detect_prefix(slide)
    content_map = _flatten_content(page_content)
    all_shapes = list(_iter_shapes(slide.shapes))
    shapes_by_name = {}
    shapes_by_exact = {}
    text_placeholders = []
    used_text_shapes = set()
    used_picture_shapes = set()
    picture_placeholders = []

    for shape in all_shapes:
        if shape.name:
            shapes_by_exact.setdefault(shape.name, shape)
            for alias in _shape_aliases(shape.name):
                shapes_by_name.setdefault(alias, shape)
            if _is_placeholder_shape(shape):
                text_placeholders.append(shape)
            if _is_picture_shape(shape):
                picture_placeholders.append(shape)

    for shape, raw_path in _iter_shapes_with_path(slide.shapes):
        label_path = _normalize_path(raw_path, prefix)
        if not label_path:
            continue
        key = tuple(label_path)
        if key not in content_map:
            continue
        value = content_map[key]

        if _is_picture_shape(shape):
            _replace_picture(slide, shape, value)
            used_picture_shapes.add(shape.name)
        elif shape.has_text_frame:
            if value:
                _set_shape_text(shape, value)
                used_text_shapes.add(shape.name)
            else:
                shape.text_frame.clear()
                used_text_shapes.add(shape.name)
        else:
            continue

    # å…¼å®¹æ—§ JSON çš„é”®åï¼Œç”¨åˆ«åæœºåˆ¶å…œåº•
    for area_name, value in page_content.items():
        if isinstance(value, dict):
            continue
        shape = None
        for candidate in _candidate_keys(area_name):
            shape = shapes_by_name.get(candidate)
            if shape:
                break
        if not shape and area_name in MANUAL_NAME_MAP:
            for exact in MANUAL_NAME_MAP[area_name]:
                shape = shapes_by_exact.get(exact)
                if shape:
                    break
        if not shape and "å­—å¹•" in area_name:
            for exact in MANUAL_NAME_MAP.get("å­—å¹•", []):
                shape = shapes_by_exact.get(exact)
                if shape:
                    break

        if not shape and any(keyword in area_name for keyword in ("å†…å®¹", "å­—å¹•")):
            if text_placeholders:
                shape = text_placeholders.pop(0)
        if not shape and any(keyword in area_name for keyword in ("å›¾ç‰‡åŒº", "å›¾ç‰‡")):
            if picture_placeholders:
                shape = picture_placeholders.pop(0)

        if not shape:
            print(f"âš ï¸  æ‰¾ä¸åˆ°åä¸ºâ€œ{area_name}â€çš„å½¢çŠ¶ï¼Œå†…å®¹å·²å¿½ç•¥ã€‚")
            continue

        if _is_picture_shape(shape):
            _replace_picture(slide, shape, value)
        elif shape.has_text_frame:
            if value:
                _set_shape_text(shape, value)
            else:
                shape.text_frame.clear()
        else:
            print(f"âš ï¸  å½¢çŠ¶â€œ{area_name}â€æ—¢ä¸æ˜¯æ–‡æœ¬ä¹Ÿä¸æ˜¯å›¾ç‰‡ï¼Œè·³è¿‡ã€‚")

    _clear_default_subtitles(all_shapes)
    _apply_layout_rules(all_shapes, slide_width)


def _clear_default_subtitles(shapes):
    """æ¸…é™¤æœªè¢«è¦†ç›–çš„å­—å¹•æˆ–é»˜è®¤è¯´æ˜æ–‡å­—ã€‚"""
    for shape in shapes:
        if not shape.has_text_frame:
            continue
        text = (shape.text_frame.text or "").strip()
        if text in SUBTITLE_TEXTS or any(keyword in text for keyword in PLACEHOLDER_KEYWORDS):
            shape.text_frame.clear()


def _apply_layout_rules(shapes, slide_width):
    """æ ¹æ®æ–‡æœ¬é•¿åº¦è‡ªåŠ¨è°ƒæ•´æ ‡é¢˜æ¡ä¸èƒŒæ™¯ã€‚"""
    for shape in shapes:
        if not shape.has_text_frame:
            continue
        name = shape.name or ""
        if not any(keyword in name for keyword in EXPANDABLE_KEYWORDS):
            continue
        _adjust_text_shape(shape, shapes, slide_width)


def _adjust_text_shape(text_shape, shapes, slide_width):
    text_width = _estimate_text_width(text_shape)
    if text_width <= 0:
        return

    limit = _find_right_limit(text_shape, shapes, slide_width) - H_PADDING
    available = max(text_shape.width, limit - text_shape.left)
    target_width = min(max(text_shape.width, text_width + H_PADDING), available)

    if target_width > text_shape.width:
        target_width = int(target_width)
        delta = target_width - text_shape.width
        text_shape.width = target_width
        bg = _find_background_shape(text_shape, shapes)
        if bg:
            bg.width = int(max(bg.width, target_width + H_PADDING))
            bg.left = min(bg.left, text_shape.left)
    else:
        shrink_ratio = available / text_width if text_width else 1
        if shrink_ratio < 1:
            _shrink_font(text_shape, shrink_ratio)


def _find_background_shape(text_shape, shapes):
    top = text_shape.top
    bottom = text_shape.top + text_shape.height
    candidate = None
    for shape in shapes:
        if shape is text_shape or shape.has_text_frame or _is_picture_shape(shape):
            continue
        overlap = min(bottom, shape.top + shape.height) - max(top, shape.top)
        if overlap <= 0:
            continue
        ratio = overlap / max(1, text_shape.height)
        if ratio < 0.6:
            continue
        if candidate is None or shape.width > candidate.width:
            candidate = shape
    return candidate


def _find_right_limit(text_shape, shapes, slide_width):
    limit = slide_width
    top = text_shape.top
    bottom = text_shape.top + text_shape.height
    for shape in shapes:
        if shape is text_shape:
            continue
        other_top = shape.top
        other_bottom = shape.top + shape.height
        overlap = min(bottom, other_bottom) - max(top, other_top)
        if overlap <= 0:
            continue
        if shape.left > text_shape.left:
            limit = min(limit, shape.left)
    return limit


def _estimate_text_width(shape):
    if not shape.has_text_frame:
        return 0

    max_line = 0
    for para in shape.text_frame.paragraphs:
        line = "".join(run.text for run in para.runs) or para.text or ""
        if not line:
            continue
        font_size = None
        for run in para.runs:
            if run.font.size:
                font_size = run.font.size.pt
                break
        if font_size is None:
            font_size = 28
        width_factor = sum(0.55 if ord(ch) < 128 else 1 for ch in line)
        line_width = width_factor * font_size * EMU_PER_PT
        max_line = max(max_line, line_width)
    return max(max_line, shape.width)


def _shrink_font(shape, ratio):
    ratio = max(ratio, 0.6)
    for para in shape.text_frame.paragraphs:
        for run in para.runs:
            if run.font.size:
                run.font.size = Pt(run.font.size.pt * ratio)


def _extract_connectors(pptx_path: Path):
    connectors = {}
    with zipfile.ZipFile(pptx_path, "r") as zf:
        for name in zf.namelist():
            match = SLIDE_RE.fullmatch(name)
            if not match:
                continue
            slide_idx = int(match.group(1))
            root = etree.fromstring(zf.read(name))
            nodes = root.xpath(".//p:cxnSp", namespaces=NSMAP)
            if nodes:
                connectors[slide_idx] = [etree.tostring(node) for node in nodes]
    return connectors


def _restore_connectors(pptx_path: Path, connectors):
    if not connectors:
        return
    with zipfile.ZipFile(pptx_path, "r") as src:
        entries = {name: src.read(name) for name in src.namelist()}
    modified = False
    for name, data in list(entries.items()):
        match = SLIDE_RE.fullmatch(name)
        if not match:
            continue
        slide_idx = int(match.group(1))
        snippets = connectors.get(slide_idx)
        if not snippets:
            continue
        root = etree.fromstring(data)
        sp_tree = root.find(".//p:spTree", namespaces=NSMAP)
        if sp_tree is None:
            continue
        for node in sp_tree.findall("p:cxnSp", namespaces=NSMAP):
            sp_tree.remove(node)
        for snippet in snippets:
            sp_tree.append(etree.fromstring(snippet))
        entries[name] = etree.tostring(root, encoding="utf-8", xml_declaration=True)
        modified = True
    if not modified:
        return
    with zipfile.ZipFile(pptx_path, "w") as dst:
        for name, data in entries.items():
            dst.writestr(name, data)


def generate_ppt(template_path, json_path, output_path):
    """å®Œæ•´æµç¨‹ï¼šå¤åˆ¶æ¨¡æ¿é¡ºåº -> å¡«å……å†…å®¹ -> è¾“å‡º PPTã€‚"""
    pages = json.loads(Path(json_path).read_text(encoding="utf-8")).get("ppt_pages", [])
    if not pages:
        raise ValueError("JSON æ–‡ä»¶ä¸­æ²¡æœ‰ ppt_pages å†…å®¹ã€‚")

    with tempfile.NamedTemporaryFile(suffix=".pptx", delete=False) as tmp:
        temp_ppt = Path(tmp.name)

    try:
        build_from_json(template_path, json_path, temp_ppt)
        connector_snapshots = _extract_connectors(temp_ppt)
        prs = Presentation(temp_ppt)
        if len(prs.slides) != len(pages):
            raise RuntimeError("ç”Ÿæˆçš„å¹»ç¯ç‰‡æ•°é‡ä¸ JSON ä¸åŒ¹é…ï¼Œæ— æ³•å¡«å……ã€‚")

        slide_width = prs.slide_width
        for slide, page in zip(prs.slides, pages):
            _fill_slide(slide, page.get("content", {}), slide_width)

        prs.save(output_path)
        _restore_connectors(Path(output_path), connector_snapshots)
    finally:
        temp_ppt.unlink(missing_ok=True)

    print(f"\nğŸ¯ å·²æ ¹æ®å†…å®¹ç”Ÿæˆ PPTï¼š{output_path}")


def main():
    parser = argparse.ArgumentParser(description="è¯»å– JSON å¹¶å¡«å……æ¨¡æ¿ç”Ÿæˆ PPT")
    parser.add_argument("--template", required=True, help="æ¨¡æ¿ PPTX è·¯å¾„")
    parser.add_argument("--json", required=True, help="æè¿°å†…å®¹çš„ JSON æ–‡ä»¶")
    parser.add_argument("--output", default="final_output.pptx", help="è¾“å‡º PPTX è·¯å¾„")
    args = parser.parse_args()

    generate_ppt(args.template, args.json, args.output)


if __name__ == "__main__":
    main()
