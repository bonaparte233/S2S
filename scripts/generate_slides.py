"""æ ¹æ® JSON æè¿°å¤åˆ¶æ¨¡æ¿ã€å¡«å……æ–‡æœ¬/å›¾ç‰‡å¹¶ç”Ÿæˆæœ€ç»ˆ PPTã€‚"""

import argparse
import json
import re
import secrets
import shutil
import tempfile
import zipfile
from datetime import datetime
from pathlib import Path
from typing import Dict, Optional

from PIL import Image
from lxml import etree
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE
from pptx.util import Pt

from archive.generatePPT_template import build_from_json


SUFFIXES = ("åŒº", "æ¡†", "æ ")
PLACEHOLDER_KEYWORDS = ("æ–‡å­—å†…å®¹", "å­—å¹•", "æ ‡é¢˜åç§°", "å†…å®¹å†…å®¹")
SUBTITLE_TEXTS = ("å­—å¹•18ptï¼Œç™½è‰²å­—ä½“æ·±è‰²æè¾¹ï¼Œæ‚¬æµ®é˜´å½±ã€‚ç¡®ä¿åœ¨ä»»ä½•åº•è‰²ä¸Šéƒ½èƒ½æ˜ç¡®æ˜¾ç¤º",)
IGNORE_KEYWORDS = ("èƒŒæ™¯", "çŸ©å½¢", "åœ†è§’", "æ¤­åœ†", "å½¢çŠ¶", "å›¾å½¢", "é®ç½©", "åº•è‰²")
EXPANDABLE_KEYWORDS = ("æ ‡é¢˜", "åç§°", "è¯¾é¢˜", "æ ç›®")
EMU_PER_PT = 12700
H_PADDING = 20000  # çº¦ 1.5 æ¯«ç±³
MANUAL_NAME_MAP = {
    "ç›®å½•å†…å®¹åŒº1": ["æ–‡æœ¬æ¡† 9"],
    "ç›®å½•å†…å®¹åŒº2": ["æ–‡æœ¬æ¡† 14"],
    "ç›®å½•å†…å®¹åŒº3": ["æ–‡æœ¬æ¡† 17"],
    "ç›®å½•å†…å®¹åŒº4": ["æ–‡æœ¬æ¡† 20"],
    # å¸¸è§å­—å¹•æ¡†
    "å­—å¹•": ["æ–‡æœ¬æ¡† 10", "æ–‡æœ¬æ¡† 32", "æ–‡æœ¬æ¡† 36", "æ–‡æœ¬æ¡† 58", "æ–‡æœ¬æ¡† 121"],
}
NSMAP = {
    "p": "http://schemas.openxmlformats.org/presentationml/2006/main",
    "a": "http://schemas.openxmlformats.org/drawingml/2006/main",
}
SLIDE_RE = re.compile(r"ppt/slides/slide(\d+)\.xml")


def _create_run_dir(base_dir: Path = Path("temp")) -> Path:
    """åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„ run ç›®å½•ï¼ŒGUI å¯æ®æ­¤æ”¶é›† PPT ä¸è°ƒè¯•æ–‡ä»¶ã€‚"""
    timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
    suffix = secrets.token_hex(2)
    run_dir = base_dir / f"slide-{timestamp}-{suffix}"
    run_dir.mkdir(parents=True, exist_ok=True)
    return run_dir


def _iter_shapes(shapes):
    """é€’å½’éå†å¹»ç¯ç‰‡ï¼ŒåŒ…å«ç»„åˆå†…éƒ¨çš„å½¢çŠ¶ã€‚"""
    for shape in shapes:
        if shape.shape_type == MSO_SHAPE_TYPE.GROUP:
            yield from _iter_shapes(shape.shapes)
        else:
            yield shape


def _iter_shapes_with_path(shapes, parent_path=None):
    """é€’å½’éå†å¹»ç¯ç‰‡ï¼Œè¿”å› (shape, è·¯å¾„)ã€‚"""
    for idx, shape in enumerate(shapes, start=1):
        name = (shape.name or "").strip() or f"å…ƒç´ {idx}"
        path = (*parent_path, name) if parent_path else (name,)
        yield shape, path
        if shape.shape_type == MSO_SHAPE_TYPE.GROUP:
            yield from _iter_shapes_with_path(shape.shapes, path)


def _is_picture_shape(shape):
    """åˆ¤æ–­å½¢çŠ¶æ˜¯å¦å……å½“å›¾ç‰‡å ä½ç¬¦ã€‚"""
    name = shape.name or ""
    if "å›¾ç‰‡åŒº" in name or name.startswith("å›¾ç‰‡"):
        return True
    if shape.shape_type == MSO_SHAPE_TYPE.PICTURE:
        return True
    if shape.is_placeholder:
        try:
            return shape.placeholder_format.type == 18
        except ValueError:
            return False
    return False


def _is_placeholder_shape(shape):
    """è¯†åˆ«æ™®é€šæ–‡æœ¬å ä½ç¬¦ï¼Œç”¨äºç›®å½•â€œæ–‡å­—æ–‡å­—â€è¿™ç±»å†…å®¹ã€‚"""
    if not shape.has_text_frame:
        return False
    text = (shape.text_frame.text or "").strip()
    name = shape.name or ""
    if name.startswith("æ–‡æœ¬æ¡†"):
        return True
    return any(keyword in text for keyword in PLACEHOLDER_KEYWORDS)


def _detect_prefix(slide):
    counter = {}
    for _, path in _iter_shapes_with_path(slide.shapes):
        for segment in path:
            prefix = _extract_prefix(segment)
            if prefix:
                counter[prefix] = counter.get(prefix, 0) + 1
    if not counter:
        return None
    return max(counter.items(), key=lambda item: item[1])[0]


def _extract_prefix(name):
    if "_" not in name:
        return None
    prefix = name.split("_", 1)[0]
    return prefix if "é¡µ" in prefix else None


def _normalize_path(path, page_prefix):
    start_idx = 0
    if page_prefix:
        start_idx = -1
        for idx, segment in enumerate(path):
            if page_prefix in segment:
                start_idx = idx
                break
        if start_idx == -1:
            return []
    trimmed = []
    for segment in path[start_idx:]:
        seg = _clean_segment(segment, page_prefix)
        if not seg:
            continue
        trimmed.append(seg)
    return trimmed


def _clean_segment(segment, page_prefix):
    seg = segment.strip()
    if not seg:
        return ""
    if page_prefix and seg.startswith(page_prefix + "_"):
        seg = seg[len(page_prefix) + 1 :]
    for keyword in IGNORE_KEYWORDS:
        if keyword in seg:
            return ""
    return seg


def _flatten_content(content):
    mapping = {}

    def walk(node, path):
        if isinstance(node, dict):
            for key, value in node.items():
                walk(value, path + (key,))
        else:
            mapping[path] = node

    walk(content or {}, tuple())
    return mapping


def _shape_aliases(name):
    """ä¸ºå½¢çŠ¶åç§°ç”Ÿæˆå¤šç§åˆ«åï¼Œæå‡åŒ¹é…æˆåŠŸç‡ã€‚"""
    aliases = set()
    clean = name.strip()
    if not clean:
        return aliases

    aliases.update({clean, clean.replace(" ", "")})

    def _add_parts(separator):
        if separator in clean:
            parts = [p for p in clean.split(separator) if p]
            for part in parts:
                aliases.add(part)
                aliases.add(part.replace(" ", ""))

    _add_parts("_")
    _add_parts("-")

    extra = set()
    for alias in aliases:
        for suf in SUFFIXES:
            if alias.endswith(suf):
                trimmed = alias[: -len(suf)]
                extra.add(trimmed)
                extra.add(trimmed.replace(" ", ""))
    aliases.update(extra)
    return aliases


def _candidate_keys(key):
    """ç»™å®š JSON ä¸­çš„é”®åï¼Œç”Ÿæˆè‹¥å¹²åŒ¹é…å€™é€‰ã€‚"""
    key = key.strip()
    variants = [key, key.replace(" ", "")]
    for suf in SUFFIXES:
        if key.endswith(suf):
            variants.append(key[: -len(suf)])
            variants.append(key[: -len(suf)].replace(" ", ""))
    seen = set()
    result = []
    for variant in variants:
        if variant and variant not in seen:
            result.append(variant)
            seen.add(variant)
    return result


def _set_shape_text(shape, text):
    """å¡«å……æ–‡æœ¬æ—¶å°½é‡ä¿æŒåŸæœ‰æ ¼å¼ã€‚"""
    if not shape.has_text_frame:
        return

    text = "" if text is None else str(text)
    lines = text.split("\n")
    tf = shape.text_frame

    if not tf.paragraphs:
        tf.add_paragraph()

    for idx, line in enumerate(lines):
        if idx < len(tf.paragraphs):
            para = tf.paragraphs[idx]
        else:
            para = tf.add_paragraph()

        if para.runs:
            para.runs[0].text = line
            for run in para.runs[1:]:
                run.text = ""
        else:
            para.text = line

    # æ¸…ç†å¤šä½™æ®µè½
    for idx in range(len(lines), len(tf.paragraphs)):
        for run in tf.paragraphs[idx].runs:
            run.text = ""

    tf.word_wrap = True


def _safe_remove_shape(shape):
    element_parent = shape.element.getparent()
    if element_parent is not None:
        element_parent.remove(shape.element)


def _replace_picture(slide, shape, image_path):
    """å°†å›¾ç‰‡å ä½ç¬¦æ›¿æ¢ä¸ºæœ¬åœ°å›¾ç‰‡ï¼Œä¿æŒä½ç½®å¤§å°æ¯”ç‡ã€‚

    å¦‚æœæ²¡æœ‰æä¾›å›¾ç‰‡è·¯å¾„æˆ–å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä¿ç•™åŸæœ‰å ä½ç¬¦ä¸åšä¿®æ”¹ã€‚
    """
    if not image_path:
        # æ²¡æœ‰æä¾›å›¾ç‰‡ï¼Œä¿ç•™åŸæœ‰å ä½ç¬¦
        print(f"â„¹ï¸  å›¾ç‰‡ä½ç½® [{shape.name}] æœªæä¾›å›¾ç‰‡ï¼Œä¿ç•™åŸæœ‰å ä½ç¬¦")
        return

    image_path = Path(image_path)
    if not image_path.is_file():
        # å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä¿ç•™åŸæœ‰å ä½ç¬¦
        print(f"âš ï¸  å›¾ç‰‡æ–‡ä»¶ä¸å¯ç”¨ï¼š{image_path}ï¼Œä¿ç•™åŸæœ‰å ä½ç¬¦")
        return

    left, top, width, height = shape.left, shape.top, shape.width, shape.height
    name = shape.name

    with Image.open(image_path) as img:
        img_w, img_h = img.size

    img_ratio = img_w / img_h
    box_ratio = width / height
    if img_ratio > box_ratio:
        new_width = width
        new_height = width / img_ratio
    else:
        new_height = height
        new_width = height * img_ratio

    new_left = int(left + (width - new_width) / 2)
    new_top = int(top + (height - new_height) / 2)
    new_width = int(new_width)
    new_height = int(new_height)

    parent_shapes = getattr(shape, "_parent", None)
    _safe_remove_shape(shape)
    if parent_shapes is None:
        # æŸäº›å ä½å±äºç»„åˆä½† XML å·²è¢«å‰¥ç¦»ï¼Œæ­¤æ—¶æ— æ³•å®‰å…¨ç§»é™¤ï¼Œç›´æ¥ä¿ç•™åŸçˆ¶å±‚
        parent_shapes = slide.shapes

    if parent_shapes is None or not hasattr(parent_shapes, "add_picture"):
        parent_shapes = slide.shapes

    new_pic = parent_shapes.add_picture(
        str(image_path), new_left, new_top, width=new_width, height=new_height
    )
    new_pic.name = name


def _fill_slide(slide, page_content, slide_width):
    """æ ¹æ® JSON å†…å®¹æŠŠæ–‡æœ¬å’Œå›¾ç‰‡å†™å…¥å¯¹åº”åŒºåŸŸã€‚"""
    prefix = _detect_prefix(slide)
    content_map = _flatten_content(page_content)
    all_shapes = list(_iter_shapes(slide.shapes))
    shapes_by_name = {}
    shapes_by_exact = {}
    text_placeholders = []
    used_text_shapes = set()
    used_picture_shapes = set()
    picture_placeholders = []

    for shape in all_shapes:
        if shape.name:
            shapes_by_exact.setdefault(shape.name, shape)
            for alias in _shape_aliases(shape.name):
                shapes_by_name.setdefault(alias, shape)
            if _is_placeholder_shape(shape):
                text_placeholders.append(shape)
            if _is_picture_shape(shape):
                picture_placeholders.append(shape)

    for shape, raw_path in _iter_shapes_with_path(slide.shapes):
        label_path = _normalize_path(raw_path, prefix)
        if not label_path:
            continue
        key = tuple(label_path)
        if key not in content_map:
            continue
        value = content_map[key]

        if _is_picture_shape(shape):
            _replace_picture(slide, shape, value)
            used_picture_shapes.add(shape.name)
        elif shape.has_text_frame:
            if value:
                _set_shape_text(shape, value)
                used_text_shapes.add(shape.name)
            else:
                shape.text_frame.clear()
                used_text_shapes.add(shape.name)
        else:
            continue

    # å…¼å®¹æ–°æ—§ JSON æ ¼å¼çš„é”®ååŒ¹é…
    for area_name, raw_value in page_content.items():
        # æ–°ç‰ˆæ ¼å¼ï¼šå€¼æ˜¯ dictï¼ŒåŒ…å« type/hint/value ç­‰å­—æ®µ
        # æ—§ç‰ˆæ ¼å¼ï¼šå€¼ç›´æ¥æ˜¯å­—ç¬¦ä¸²
        field_type = None  # ä» JSON è·å–çš„å­—æ®µç±»å‹
        if isinstance(raw_value, dict):
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°ç‰ˆæ ¼å¼ï¼ˆæœ‰ type å’Œ value å­—æ®µï¼‰
            if "type" in raw_value and "value" in raw_value:
                value = raw_value.get("value", "")
                field_type = raw_value.get("type", "text")  # text æˆ– image
            else:
                # åµŒå¥—çš„æ—§ç‰ˆç»“æ„ï¼Œè·³è¿‡è®© _flatten_content å¤„ç†
                continue
        else:
            value = raw_value

        # é¦–å…ˆå°è¯•ç²¾ç¡®åŒ¹é…å½¢çŠ¶åç§°ï¼ˆå‘å¯¼æ¨¡å¼å‘½ååçš„å½¢çŠ¶ï¼‰
        shape = shapes_by_exact.get(area_name)

        # å¦‚æœç²¾ç¡®åŒ¹é…å¤±è´¥ï¼Œå°è¯•åˆ«ååŒ¹é…
        if not shape:
            for candidate in _candidate_keys(area_name):
                shape = shapes_by_name.get(candidate)
                if shape:
                    break

        # å°è¯•æ‰‹åŠ¨æ˜ å°„
        if not shape and area_name in MANUAL_NAME_MAP:
            for exact in MANUAL_NAME_MAP[area_name]:
                shape = shapes_by_exact.get(exact)
                if shape:
                    break
        if not shape and "å­—å¹•" in area_name:
            for exact in MANUAL_NAME_MAP.get("å­—å¹•", []):
                shape = shapes_by_exact.get(exact)
                if shape:
                    break

        # å°è¯•å ä½ç¬¦åŒ¹é…
        if not shape and any(keyword in area_name for keyword in ("å†…å®¹", "å­—å¹•")):
            if text_placeholders:
                shape = text_placeholders.pop(0)
        if not shape and any(keyword in area_name for keyword in ("å›¾ç‰‡åŒº", "å›¾ç‰‡")):
            if picture_placeholders:
                shape = picture_placeholders.pop(0)

        if not shape:
            print(f"âš ï¸  æ‰¾ä¸åˆ°åä¸ºã€Œ{area_name}ã€çš„å½¢çŠ¶ï¼Œå†…å®¹å·²å¿½ç•¥ã€‚")
            continue

        # è·³è¿‡å·²å¤„ç†çš„å½¢çŠ¶
        if shape.name in used_text_shapes or shape.name in used_picture_shapes:
            continue

        # æ ¹æ® JSON ä¸­çš„ type å­—æ®µæˆ–å½¢çŠ¶ç±»å‹åˆ¤æ–­å¤„ç†æ–¹å¼
        is_image = field_type == "image" if field_type else _is_picture_shape(shape)
        
        if is_image:
            # å›¾ç‰‡ç±»å‹ï¼šæ²¡æœ‰å€¼æ—¶ä¿ç•™åŸå ä½ç¬¦
            _replace_picture(slide, shape, value)
            used_picture_shapes.add(shape.name)
        elif shape.has_text_frame:
            # æ–‡æœ¬ç±»å‹ï¼šæ²¡æœ‰å€¼æ—¶æ¸…ç©ºæ–‡æœ¬æ¡†
            if value:
                _set_shape_text(shape, value)
            else:
                shape.text_frame.clear()
            used_text_shapes.add(shape.name)
        else:
            print(f"âš ï¸  å½¢çŠ¶ã€Œ{area_name}ã€æ—¢ä¸æ˜¯æ–‡æœ¬ä¹Ÿä¸æ˜¯å›¾ç‰‡ï¼Œè·³è¿‡ã€‚")

    _clear_default_subtitles(all_shapes)
    _apply_layout_rules(all_shapes, slide_width)


def _clear_default_subtitles(shapes):
    """æ¸…é™¤æœªè¢«è¦†ç›–çš„å­—å¹•æˆ–é»˜è®¤è¯´æ˜æ–‡å­—ã€‚"""
    for shape in shapes:
        if not shape.has_text_frame:
            continue
        text = (shape.text_frame.text or "").strip()
        if text in SUBTITLE_TEXTS or any(
            keyword in text for keyword in PLACEHOLDER_KEYWORDS
        ):
            shape.text_frame.clear()


def _apply_layout_rules(shapes, slide_width):
    """æ ¹æ®æ–‡æœ¬é•¿åº¦è‡ªåŠ¨è°ƒæ•´æ ‡é¢˜æ¡ä¸èƒŒæ™¯ã€‚"""
    for shape in shapes:
        if not shape.has_text_frame:
            continue
        name = shape.name or ""
        if not any(keyword in name for keyword in EXPANDABLE_KEYWORDS):
            continue
        _adjust_text_shape(shape, shapes, slide_width)


def _adjust_text_shape(text_shape, shapes, slide_width):
    text_width = _estimate_text_width(text_shape)
    if text_width <= 0:
        return

    limit = _find_right_limit(text_shape, shapes, slide_width) - H_PADDING
    available = max(text_shape.width, limit - text_shape.left)
    target_width = min(max(text_shape.width, text_width + H_PADDING), available)

    if target_width > text_shape.width:
        target_width = int(target_width)
        delta = target_width - text_shape.width
        text_shape.width = target_width
        bg = _find_background_shape(text_shape, shapes)
        if bg:
            bg.width = int(max(bg.width, target_width + H_PADDING))
            bg.left = min(bg.left, text_shape.left)
    else:
        shrink_ratio = available / text_width if text_width else 1
        if shrink_ratio < 1:
            _shrink_font(text_shape, shrink_ratio)


def _find_background_shape(text_shape, shapes):
    top = text_shape.top
    bottom = text_shape.top + text_shape.height
    candidate = None
    for shape in shapes:
        if shape is text_shape or shape.has_text_frame or _is_picture_shape(shape):
            continue
        overlap = min(bottom, shape.top + shape.height) - max(top, shape.top)
        if overlap <= 0:
            continue
        ratio = overlap / max(1, text_shape.height)
        if ratio < 0.6:
            continue
        if candidate is None or shape.width > candidate.width:
            candidate = shape
    return candidate


def _find_right_limit(text_shape, shapes, slide_width):
    limit = slide_width
    top = text_shape.top
    bottom = text_shape.top + text_shape.height
    for shape in shapes:
        if shape is text_shape:
            continue
        other_top = shape.top
        other_bottom = shape.top + shape.height
        overlap = min(bottom, other_bottom) - max(top, other_top)
        if overlap <= 0:
            continue
        if shape.left > text_shape.left:
            limit = min(limit, shape.left)
    return limit


def _estimate_text_width(shape):
    if not shape.has_text_frame:
        return 0

    max_line = 0
    for para in shape.text_frame.paragraphs:
        line = "".join(run.text for run in para.runs) or para.text or ""
        if not line:
            continue
        font_size = None
        for run in para.runs:
            if run.font.size:
                font_size = run.font.size.pt
                break
        if font_size is None:
            font_size = 28
        width_factor = sum(0.55 if ord(ch) < 128 else 1 for ch in line)
        line_width = width_factor * font_size * EMU_PER_PT
        max_line = max(max_line, line_width)
    return max(max_line, shape.width)


def _shrink_font(shape, ratio):
    ratio = max(ratio, 0.6)
    for para in shape.text_frame.paragraphs:
        for run in para.runs:
            if run.font.size:
                run.font.size = Pt(run.font.size.pt * ratio)


def _extract_connectors(pptx_path: Path):
    connectors = {}
    with zipfile.ZipFile(pptx_path, "r") as zf:
        for name in zf.namelist():
            match = SLIDE_RE.fullmatch(name)
            if not match:
                continue
            slide_idx = int(match.group(1))
            root = etree.fromstring(zf.read(name))
            nodes = root.xpath(".//p:cxnSp", namespaces=NSMAP)
            if nodes:
                connectors[slide_idx] = [etree.tostring(node) for node in nodes]
    return connectors


def _restore_connectors(pptx_path: Path, connectors):
    if not connectors:
        return
    with zipfile.ZipFile(pptx_path, "r") as src:
        entries = {name: src.read(name) for name in src.namelist()}
    modified = False
    for name, data in list(entries.items()):
        match = SLIDE_RE.fullmatch(name)
        if not match:
            continue
        slide_idx = int(match.group(1))
        snippets = connectors.get(slide_idx)
        if not snippets:
            continue
        root = etree.fromstring(data)
        sp_tree = root.find(".//p:spTree", namespaces=NSMAP)
        if sp_tree is None:
            continue
        for node in sp_tree.findall("p:cxnSp", namespaces=NSMAP):
            sp_tree.remove(node)
        for snippet in snippets:
            sp_tree.append(etree.fromstring(snippet))
        entries[name] = etree.tostring(root, encoding="utf-8", xml_declaration=True)
        modified = True
    if not modified:
        return
    with zipfile.ZipFile(pptx_path, "w") as dst:
        for name, data in entries.items():
            dst.writestr(name, data)


def render_slides(
    template_path: Path,
    config: Dict,
    output_name: str,
    run_dir: Optional[Path] = None,
) -> Dict:
    """æ¸²æŸ“å…¥å£ï¼Œä¾› GUI/CLI å¤ç”¨ï¼Œè¿”å› PPT è·¯å¾„å’Œ run ç›®å½•ä¿¡æ¯ã€‚"""
    pages = config.get("ppt_pages", [])
    if not pages:
        raise ValueError("JSON æ•°æ®ä¸­æ²¡æœ‰ ppt_pages å†…å®¹ã€‚")

    run_dir = run_dir or _create_run_dir()
    run_dir.mkdir(parents=True, exist_ok=True)
    output_path = run_dir / output_name

    with tempfile.NamedTemporaryFile(suffix=".pptx", delete=False) as tmp:
        temp_ppt = Path(tmp.name)

    try:
        tmp_json = run_dir / "config.json"
        tmp_json.write_text(
            json.dumps(config, ensure_ascii=False, indent=2), encoding="utf-8"
        )

        build_from_json(template_path, tmp_json, temp_ppt)
        connector_snapshots = _extract_connectors(temp_ppt)
        prs = Presentation(temp_ppt)
        if len(prs.slides) != len(pages):
            raise RuntimeError("ç”Ÿæˆçš„å¹»ç¯ç‰‡æ•°é‡ä¸ JSON ä¸åŒ¹é…ï¼Œæ— æ³•å¡«å……ã€‚")

        slide_width = prs.slide_width
        for slide, page in zip(prs.slides, pages):
            _fill_slide(slide, page.get("content", {}), slide_width)

        prs.save(output_path)
        _restore_connectors(output_path, connector_snapshots)
    finally:
        temp_ppt.unlink(missing_ok=True)

    return {"output_path": output_path, "run_dir": run_dir, "slides": len(pages)}


def main():
    parser = argparse.ArgumentParser(description="è¯»å– JSON å¹¶å¡«å……æ¨¡æ¿ç”Ÿæˆ PPT")
    parser.add_argument("--template", required=True, help="æ¨¡æ¿ PPTX è·¯å¾„")
    parser.add_argument("--json", required=True, help="æè¿°å†…å®¹çš„ JSON æ–‡ä»¶")
    parser.add_argument(
        "--output", default="final_output.pptx", help="è¾“å‡º PPTX æ–‡ä»¶åæˆ–è·¯å¾„"
    )
    parser.add_argument(
        "--run-dir", default=None, help="è¾“å‡º run ç›®å½•ï¼ˆé»˜è®¤ temp/run-...ï¼‰"
    )
    args = parser.parse_args()

    config = json.loads(Path(args.json).read_text(encoding="utf-8"))
    run_dir = Path(args.run_dir) if args.run_dir else None
    result = render_slides(Path(args.template), config, Path(args.output).name, run_dir)
    final_path = result["output_path"]
    if Path(args.output).is_absolute():
        Path(args.output).parent.mkdir(parents=True, exist_ok=True)
        shutil.copyfile(final_path, Path(args.output))
        print(f"ğŸ“„ å¦å­˜ä¸ºï¼š{args.output}")
    print(f"ğŸ¯ å·²æ ¹æ®å†…å®¹ç”Ÿæˆ PPTï¼š{final_path}")


if __name__ == "__main__":
    main()
