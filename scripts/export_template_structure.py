"""
ä»æ¨¡æ¿ PPT ä¸­æå–å¯ä¾›å¤§æ¨¡å‹å‚è€ƒçš„ JSON ç»“æ„ã€‚

ç”¨æ³•ç¤ºä¾‹ï¼š
python scripts/export_template_structure.py \
    --template template/template.pptx \
    --output template/exported_template.json \
    --mode semantic \
    --include 1,2,3,4,8,12,15,16,17,18,21,26,27,28 \
    --ai-enrich --llm-provider deepseek --llm-model deepseek-chat
"""

from __future__ import annotations

import argparse
import json
import math
import os
import re
from collections import Counter, OrderedDict
from pathlib import Path
from typing import Dict, List, Optional, Sequence, Tuple

from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

GENERIC_NAME_PATTERN = re.compile(
    r"^(å›¾ç‰‡|æ–‡æœ¬æ¡†|çŸ©å½¢|åœ†è§’|ä»»æ„|æ¤­åœ†|çº¿æ¡|ç»„åˆ|å¯¹è±¡|table|textbox|picture|group|èƒŒæ™¯|subtitle|caption)",
    re.IGNORECASE,
)


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="ä» PPT æ¨¡æ¿å¯¼å‡ºç¬¦åˆ template.json ç»“æ„çš„æè¿°æ–‡ä»¶ã€‚"
    )
    parser.add_argument("--template", required=True, help="PPTX æ¨¡æ¿è·¯å¾„")
    parser.add_argument("--output", required=True, help="å¯¼å‡º JSON çš„è¾“å‡ºè·¯å¾„")
    parser.add_argument(
        "--mode",
        choices=("semantic", "text"),
        default="semantic",
        help=(
            "semanticï¼šä»…å¯¼å‡ºå‘½åè§„èŒƒï¼ˆå«â€œxxåŒºâ€ç­‰ï¼‰çš„å…ƒç´ ï¼›"
            "textï¼šå¯¼å‡ºæ‰€æœ‰å¯ç¼–è¾‘æ–‡æœ¬æ¡†ï¼ˆå¿½ç•¥å›¾ç‰‡/èƒŒæ™¯ï¼‰ã€‚"
        ),
    )
    parser.add_argument(
        "--include",
        help="å¯é€‰ï¼Œé€—å·åˆ†éš”çš„é¡µç åˆ—è¡¨ï¼Œä»…å¯¼å‡ºè¿™äº›å¹»ç¯ç‰‡ï¼Œä¾‹å¦‚ï¼š1,2,4",
    )
    parser.add_argument(
        "--ai-enrich",
        action="store_true",
        help="ä½¿ç”¨ AI è‡ªåŠ¨å¡«å…… hintã€requiredã€max_chars å’Œ notes å­—æ®µ",
    )
    parser.add_argument(
        "--llm-provider",
        choices=("deepseek", "local", "qwen"),
        default="deepseek",
        help="LLM æä¾›å•†ï¼ˆä»…åœ¨ --ai-enrich æ—¶æœ‰æ•ˆï¼‰",
    )
    parser.add_argument(
        "--llm-model",
        help="LLM æ¨¡å‹åç§°ï¼ˆä»…åœ¨ --ai-enrich æ—¶æœ‰æ•ˆï¼‰",
    )
    parser.add_argument(
        "--llm-base-url",
        help="LLM æœåŠ¡å™¨åœ°å€ï¼ˆä»…åœ¨ --ai-enrich æ—¶æœ‰æ•ˆï¼‰",
    )
    return parser.parse_args()


def is_meaningful_name(name: str) -> bool:
    name = name.strip()
    if not name:
        return False
    if GENERIC_NAME_PATTERN.match(name):
        return False
    if "_" in name:
        return True
    if re.search(r"\d", name):
        return False
    return True


def sanitize_name(name: str, fallback: str) -> str:
    cleaned = name.strip()
    return cleaned or fallback


def flatten_text(shape) -> str:
    if not shape.has_text_frame:
        return ""
    parts = [para.text for para in shape.text_frame.paragraphs]
    return "\n".join(part for part in parts if part)


def estimate_max_chars(sample: str) -> int:
    sample = re.sub(r"\s+", "", sample or "")
    length = len(sample)
    if length == 0:
        return 20
    return max(6, min(60, math.ceil(length * 1.5)))


def should_include_text_shape(
    name: str, text: str, mode: str, context_has_semantics: bool
) -> bool:
    if not text.strip():
        return False
    if mode == "semantic":
        if is_meaningful_name(name):
            return True
        return context_has_semantics
    if text.strip().startswith("å­—å¹•"):
        return False
    return True


def should_include_group(name: str, mode: str) -> bool:
    if mode == "text":
        return False
    return is_meaningful_name(name)


def is_image_shape(shape) -> bool:
    return shape.shape_type in {
        MSO_SHAPE_TYPE.PICTURE,
        MSO_SHAPE_TYPE.LINKED_PICTURE,
    }


def infer_page_type(slide, fallback: str) -> str:
    candidates: Counter[str] = Counter()

    def register(name: str) -> None:
        name = name.strip()
        if name:
            candidates[name] += 1

    for shape in slide.shapes:
        name = shape.name.strip()
        if not name:
            continue
        meaningful = is_meaningful_name(name)
        if "_" in name and meaningful:
            prefix = name.split("_", 1)[0]
            if "é¡µ" in prefix:
                register(prefix)
        if meaningful and "é¡µ" in name:
            register(name)
        if meaningful and "å¤šå­—ç‰ˆ" in name:
            register("ç« èŠ‚é¡µå¤šå­—ç‰ˆ")
            register("ç« èŠ‚é¡µå¤šå­—ç‰ˆ")
        if meaningful and "ç« èŠ‚" in name:
            register("ç« èŠ‚é¡µ")
        if meaningful and name.startswith("å›¾æ–‡é¡µ"):
            register(name)
        if meaningful and name.startswith("æ–‡å­—é¡µ"):
            register(name)

    if candidates:
        best = candidates.most_common()
        top = best[0][1]
        tied = [name for name, cnt in best if cnt == top]
        return max(tied, key=len)

    texts = " ".join(
        flatten_text(shape) for shape in slide.shapes if shape.has_text_frame
    )
    keyword_map = [
        ("ç›®å½•", "ç›®å½•é¡µ"),
        ("ä¸»è®²", "ä¸»è®²äººé¡µ"),
        ("ç« èŠ‚", "ç« èŠ‚é¡µ"),
        ("è¿‡æ¸¡", "è¿‡æ¸¡é¡µ"),
        ("å›¾æ–‡", "å›¾æ–‡é¡µ"),
    ]
    for kw, page in keyword_map:
        if kw in texts:
            return page
    return fallback


def add_field(container: OrderedDict, path: Sequence[str], payload: Dict) -> None:
    cursor = container
    for key in path[:-1]:
        cursor = cursor.setdefault(key, OrderedDict())
    cursor[path[-1]] = payload


def collect_fields(slide, mode: str) -> Tuple[OrderedDict, int, int]:
    content: OrderedDict = OrderedDict()
    text_slots = 0
    image_slots = 0
    auto_counters: Dict[str, int] = {}

    def visit(shape, context: Tuple[str, ...], context_has_semantics: bool):
        nonlocal text_slots, image_slots
        name = shape.name.strip()
        has_semantics = context_has_semantics or is_meaningful_name(name)

        if shape.shape_type == MSO_SHAPE_TYPE.GROUP:
            new_context = context
            new_semantics = context_has_semantics
            if should_include_group(name, mode):
                new_context = context + (
                    sanitize_name(name, f"åŒºåŸŸ{len(context) + 1}"),
                )
                new_semantics = True
            for child in shape.shapes:
                visit(child, new_context, new_semantics)
            return

        if mode == "semantic" and is_image_shape(shape) and is_meaningful_name(name):
            field_name = sanitize_name(name.split("_")[-1], name)
            add_field(
                content,
                context + (field_name,),
                {
                    "type": "image",
                    "hint": f"ä¸ºâ€œ{field_name}â€æä¾›å›¾ç‰‡è·¯å¾„",
                    "required": True,
                    "value": "",
                    "preferred_format": "png/jpg",
                },
            )
            image_slots += 1
            return

        if shape.has_text_frame:
            text = flatten_text(shape).strip()
            if not should_include_text_shape(name, text, mode, context_has_semantics):
                return

            key_base = name if is_meaningful_name(name) else None
            if not key_base:
                prefix = "æ–‡æœ¬"
                auto_counters[prefix] = auto_counters.get(prefix, 0) + 1
                key_base = f"{prefix}{auto_counters[prefix]}"

            field_path = context + (sanitize_name(key_base, key_base),)
            add_field(
                content,
                field_path,
                {
                    "type": "text",
                    "hint": f"å¡«å†™â€œ{field_path[-1]}â€çš„å†…å®¹",
                    "required": True,
                    "value": "",
                    "max_chars": estimate_max_chars(text),
                },
            )
            text_slots += 1

    for shp in slide.shapes:
        visit(shp, tuple(), False)

    return content, text_slots, image_slots


def build_manifest_entry(
    page_num: int, page_type: str, text_slots: int, image_slots: int
) -> Dict:
    return {
        "template_page_num": page_num,
        "page_type": page_type,
        "text_slots": text_slots,
        "image_slots": image_slots,
    }


def export_template_structure(
    template_path: Path, mode: str, include_pages: Optional[Sequence[int]]
) -> Dict:
    prs = Presentation(str(template_path))
    data_manifest: List[Dict] = []
    ppt_pages: List[Dict] = []
    include_set = set(include_pages) if include_pages else None

    for idx, slide in enumerate(prs.slides, start=1):
        if include_set and idx not in include_set:
            continue
        page_type = infer_page_type(slide, fallback=f"æ¨¡æ¿ç¬¬{idx}é¡µ")
        content, text_slots, image_slots = collect_fields(slide, mode)
        if not content and mode == "semantic":
            continue
        manifest_entry = build_manifest_entry(idx, page_type, text_slots, image_slots)
        page_payload = {
            "page_type": page_type,
            "template_page_num": idx,
            "content": content,
            "meta": {
                "layout": "auto-generated",
                "scene": [],
                "style": "auto",
                "text_slots": text_slots,
                "image_slots": image_slots,
                "notes": (
                    "ç”± export_template_structure.py è‡ªåŠ¨æå–ã€‚"
                    "è¯·æ ¹æ®å®é™…æ¨¡æ¿è¡¥å……æ›´ä¸°å¯Œçš„æè¿°ã€‚"
                ),
            },
        }
        data_manifest.append(manifest_entry)
        ppt_pages.append(page_payload)

    return {"manifest": data_manifest, "ppt_pages": ppt_pages}


def ai_enrich_template(
    template_data: Dict,
    llm_provider: str = "deepseek",
    llm_model: Optional[str] = None,
    llm_base_url: Optional[str] = None,
) -> Dict:
    """ä½¿ç”¨ AI è‡ªåŠ¨å¡«å……æ¨¡æ¿é…ç½®ä¸­çš„ hintã€requiredã€max_chars å’Œ notes å­—æ®µã€‚

    Args:
        template_data: ä» export_template_structure ç”Ÿæˆçš„æ¨¡æ¿æ•°æ®
        llm_provider: LLM æä¾›å•† (deepseek/local/qwen)
        llm_model: LLM æ¨¡å‹åç§°
        llm_base_url: LLM æœåŠ¡å™¨åœ°å€

    Returns:
        å¡«å……åçš„æ¨¡æ¿æ•°æ®
    """
    # Import LLM client
    try:
        from scripts.llm_client import BaseLLM, DeepSeekLLM, LocalLLM, QwenVLLM
    except ImportError:
        # Fallback for when running from web context
        from llm_client import BaseLLM, DeepSeekLLM, LocalLLM, QwenVLLM

    # Initialize LLM
    llm: BaseLLM
    provider = llm_provider.lower()
    if provider == "deepseek":
        llm = DeepSeekLLM(model=llm_model or "deepseek-chat")
    elif provider == "local":
        llm = LocalLLM(model=llm_model, base_url=llm_base_url)
    elif provider == "qwen":
        if not llm_base_url:
            llm_base_url = os.getenv("QWEN_VLLM_BASE_URL")
        if not llm_base_url:
            raise ValueError(
                "Qwen provider éœ€è¦æä¾› --llm-base-url æˆ–è®¾ç½® QWEN_VLLM_BASE_URL"
            )
        llm = QwenVLLM(base_url=llm_base_url)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„ LLM æä¾›å•†ï¼š{llm_provider}")

    print(f"ğŸ¤– ä½¿ç”¨ {llm_provider} è¿›è¡Œ AI å¡«å……...")

    # Process each page
    enriched_data = template_data.copy()
    enriched_data["ppt_pages"] = []

    for page_idx, page in enumerate(template_data["ppt_pages"], start=1):
        print(
            f"  å¤„ç†ç¬¬ {page_idx}/{len(template_data['ppt_pages'])} é¡µ: {page['page_type']}"
        )

        # Build prompt for this page
        page_type = page["page_type"]
        template_page_num = page["template_page_num"]
        fields = page.get("content", {})

        # Create field summary
        field_names = list(fields.keys())
        field_summary = "\n".join([f"  - {name}" for name in field_names])

        prompt = f"""ä½ æ˜¯ä¸€ä¸ª PPT æ¨¡æ¿é…ç½®ä¸“å®¶ã€‚ç°åœ¨éœ€è¦ä¸ºä¸€ä¸ª PPT æ¨¡æ¿é¡µé¢å¡«å†™é…ç½®ä¿¡æ¯ã€‚

é¡µé¢ä¿¡æ¯ï¼š
- é¡µé¢ç±»å‹ï¼š{page_type}
- æ¨¡æ¿é¡µç ï¼š{template_page_num}
- å­—æ®µåˆ—è¡¨ï¼š
{field_summary}

è¯·ä¸ºè¿™ä¸ªé¡µé¢ç”Ÿæˆé…ç½®ä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š
1. é¡µé¢è¯´æ˜ (notes)ï¼šç®€è¦æè¿°è¿™ä¸€é¡µçš„ç”¨é€”å’Œå†…å®¹è¦æ±‚ï¼ˆ1-2å¥è¯ï¼‰
2. æ¯ä¸ªå­—æ®µçš„é…ç½®ï¼š
   - hintï¼šæç¤ºå¤§æ¨¡å‹è¯¥å­—æ®µåº”è¯¥å¡«å†™ä»€ä¹ˆå†…å®¹ï¼ˆç®€æ´æ˜äº†ï¼‰
   - requiredï¼šè¯¥å­—æ®µæ˜¯å¦å¿…å¡«ï¼ˆtrue/falseï¼‰
   - max_charsï¼šè¯¥å­—æ®µçš„æœ€å¤§å­—ç¬¦æ•°ï¼ˆåˆç†ä¼°è®¡ï¼‰

è¯·ä»¥ JSON æ ¼å¼è¿”å›ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{{
  "notes": "é¡µé¢è¯´æ˜æ–‡å­—",
  "fields": {{
    "å­—æ®µå1": {{
      "hint": "æç¤ºæ–‡å­—",
      "required": true,
      "max_chars": 20
    }},
    "å­—æ®µå2": {{
      "hint": "æç¤ºæ–‡å­—",
      "required": false,
      "max_chars": 50
    }}
  }}
}}

æ³¨æ„ï¼š
- notes è¦ç®€æ´æ˜äº†ï¼Œå¸®åŠ©å¤§æ¨¡å‹ç†è§£é¡µé¢ç”¨é€”
- hint è¦å…·ä½“ï¼Œè¯´æ˜è¯¥å­—æ®µåº”è¯¥å¡«ä»€ä¹ˆå†…å®¹
- required æ ¹æ®å­—æ®µçš„é‡è¦æ€§åˆ¤æ–­
- max_chars è¦åˆç†ï¼Œè€ƒè™‘é¡µé¢å¸ƒå±€å’Œå†…å®¹éœ€æ±‚
- åªè¿”å› JSONï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—"""

        try:
            # Call LLM
            response = llm.generate(
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
            )

            # Parse response
            # Try to extract JSON from response
            json_match = re.search(r"\{[\s\S]*\}", response)
            if json_match:
                ai_config = json.loads(json_match.group())
            else:
                ai_config = json.loads(response)

            # Update page notes
            if "notes" in ai_config:
                page["meta"]["notes"] = ai_config["notes"]

            # Update field configurations
            if "fields" in ai_config:
                for field_name, field_config in ai_config["fields"].items():
                    if field_name in fields:
                        if "hint" in field_config:
                            fields[field_name]["hint"] = field_config["hint"]
                        if "required" in field_config:
                            fields[field_name]["required"] = field_config["required"]
                        if "max_chars" in field_config:
                            fields[field_name]["max_chars"] = field_config["max_chars"]

            print(f"    âœ… æˆåŠŸå¡«å……")

        except Exception as e:
            print(f"    âš ï¸  AI å¡«å……å¤±è´¥: {e}")
            print(f"    ä½¿ç”¨é»˜è®¤é…ç½®")

        enriched_data["ppt_pages"].append(page)

    print("âœ… AI å¡«å……å®Œæˆ")
    return enriched_data


def main() -> None:
    args = parse_args()
    template_path = Path(args.template)
    if not template_path.exists():
        raise FileNotFoundError(f"æ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨ï¼š{template_path}")

    include_pages = None
    if args.include:
        include_pages = [
            int(num.strip()) for num in args.include.split(",") if num.strip()
        ]

    data = export_template_structure(template_path, args.mode, include_pages)

    # AI enrichment if requested
    if args.ai_enrich:
        data = ai_enrich_template(
            template_data=data,
            llm_provider=args.llm_provider,
            llm_model=args.llm_model,
            llm_base_url=args.llm_base_url,
        )

    output_path = Path(args.output)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with output_path.open("w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    print(f"å·²å¯¼å‡º {len(data['ppt_pages'])} ä¸ªæ¨¡æ¿é¡µé¢ -> {output_path}")


if __name__ == "__main__":
    main()
