"""æ ¹æ® DOCX è®²ç¨¿å’Œæ¨¡æ¿å®šä¹‰ç”Ÿæˆ JSONï¼Œå¯é€‰è°ƒç”¨ DeepSeek LLMã€‚"""

from __future__ import annotations

import argparse
import json
import re
import secrets
import shutil
from datetime import datetime
from pathlib import Path
import os
from typing import Any, Dict, List, Optional, Tuple

from docx import Document
from docx.oxml.ns import qn

from scripts.llm_client import (
    BaseLLM,
    DeepSeekLLM,
    GLMLLM,
    LocalLLM,
    QwenVLLM,
    TaichuLLM,
)
import base64
import mimetypes

MARKER_RE = re.compile(r"ã€PPT(\d+)ã€‘")
IMAGE_NAME_TEMPLATE = "doc_image_{idx}.{ext}"

# è°ƒè¯•æ ‡å¿—ï¼šè®¾ç½®ä¸º True æ—¶æ‰“å° LLM è¯·æ±‚å’Œå“åº”
DEBUG_LLM = os.getenv("DEBUG_LLM", "false").lower() in ("true", "1", "yes")


def _create_run_dir(base_dir: Path = Path("temp")) -> Path:
    """åˆ›å»ºå¸¦æ—¶é—´æˆ³å‰ç¼€çš„è¿è¡Œç›®å½•ï¼Œæ–¹ä¾¿å‰ç«¯ä¸€æ¬¡å¤„ç†å¯¹åº”åˆ°å•ç‹¬ç›®å½•ã€‚"""
    timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
    suffix = secrets.token_hex(2)
    run_dir = base_dir / f"script-{timestamp}-{suffix}"
    run_dir.mkdir(parents=True, exist_ok=True)
    return run_dir


def parse_docx_blocks(doc_path: str, image_dir: Path) -> Tuple[List[Dict], bool, Dict]:
    """è¯»å– DOCX å¹¶æŒ‰ç…§ PPT æ ‡è®°æ‹†åˆ†å†…å®¹ï¼ŒåŒæ—¶ä¿å­˜æå–çš„å›¾ç‰‡ä¸è¯¾ç¨‹å…ƒä¿¡æ¯ã€‚"""
    doc = Document(doc_path)
    image_dir.mkdir(parents=True, exist_ok=True)
    slides: List[Dict] = []
    current: Optional[Dict] = None
    buffer: List[str] = []
    has_marker = False
    image_counter = 1
    metadata: Dict[str, str] = {}

    def flush():
        nonlocal current, buffer
        if current is None and buffer:
            slides.append(
                {"template_hint": None, "text": "\n".join(buffer).strip(), "images": []}
            )
        elif current:
            current["text"] = "\n".join(buffer).strip()
            slides.append(current)
        buffer = []
        current = None

    def ensure_block():
        nonlocal current
        if current is None:
            current = {"template_hint": None, "text": "", "images": []}

    def attach_images(paths: List[str]):
        if not paths:
            return
        ensure_block()
        current.setdefault("images", []).extend(paths)

    def extract_images(paragraph) -> List[str]:
        nonlocal image_counter
        images = []
        for element in paragraph._p.iter():
            if element.tag not in {qn("a:blip"), qn("pic:blip")}:
                continue
            r_id = element.get(qn("r:embed"))
            if not r_id:
                continue
            part = paragraph.part.related_parts.get(r_id)
            if not part:
                continue
            ext = part.filename.split(".")[-1].lower() or "png"
            filename = image_dir / IMAGE_NAME_TEMPLATE.format(
                idx=image_counter, ext=ext
            )
            with open(filename, "wb") as f:
                f.write(part.blob)
            images.append(str(filename))
            image_counter += 1
        return images

    for para in doc.paragraphs:
        text = para.text
        stripped = text.strip()
        meta_match = re.match(r"^(è¯¾ç¨‹åç§°|å­¦é™¢åç§°|ä¸»è®²æ•™å¸ˆ)[ï¼š:]\s*(.+)$", stripped)
        if meta_match:
            key = meta_match.group(1)
            value = meta_match.group(2).strip()
            if key == "è¯¾ç¨‹åç§°":
                metadata["course"] = value
            elif key == "å­¦é™¢åç§°":
                metadata["college"] = value
            elif key == "ä¸»è®²æ•™å¸ˆ":
                metadata["lecturer"] = value
            continue
        images = extract_images(para)
        if images:
            attach_images(images)
            for img_path in images:
                buffer.append(f"[å›¾ç‰‡èµ„æº: {img_path}]")

        matches = list(MARKER_RE.finditer(text))
        if matches:
            idx = 0
            for match in matches:
                prefix = text[idx : match.start()].strip()
                if prefix:
                    buffer.append(prefix)
                flush()
                has_marker = True
                current = {
                    "template_hint": int(match.group(1)),
                    "text": "",
                    "images": [],
                }
                idx = match.end()
            remainder = text[idx:].strip()
            if remainder:
                buffer.append(remainder)
            continue

        if stripped:
            buffer.append(stripped)

    flush()
    if not slides:
        full_text = "\n".join(p.text.strip() for p in doc.paragraphs if p.text.strip())
        slides.append({"template_hint": None, "text": full_text, "images": []})
    return slides, has_marker, metadata


def load_template_defs(template_json: str, template_list: str) -> Dict[int, Dict]:
    data = json.loads(Path(template_json).read_text(encoding="utf-8"))
    allowed = None
    if template_list and Path(template_list).exists():
        allowed = {
            int(item.strip())
            for item in Path(template_list)
            .read_text(encoding="utf-8")
            .replace(",", " ")
            .split()
            if item.strip().isdigit()
        }
    templates = {}
    manifest = {
        item["template_page_num"]: item
        for item in data.get("manifest", [])
        if "template_page_num" in item
    }
    for page in data.get("ppt_pages", []):
        num = page.get("template_page_num")
        if not isinstance(num, int):
            continue
        if allowed and num not in allowed:
            continue
        schema = page.get("content", {})
        fields = _collect_fields(schema)
        templates[num] = {
            "page_type": page.get("page_type", f"æ¨¡æ¿ç¬¬{num}é¡µ"),
            "schema": schema,
            "meta": page.get("meta", {}) or manifest.get(num, {}),
            "text_fields": [field for field in fields if not field["is_image"]],
            "image_fields": [field for field in fields if field["is_image"]],
        }
    if not templates:
        raise ValueError("æ¨¡æ¿åˆ—è¡¨ä¸ºç©ºï¼Œæ— æ³•åŒ¹é…ã€‚")
    return templates


def _collect_fields(schema, prefix=None):
    results = []
    prefix = prefix or ()
    if isinstance(schema, dict):
        if "type" in schema and "value" in schema:
            field_type = schema.get("type") or "text"
            results.append(
                {
                    "path": prefix,
                    "is_image": field_type.lower() == "image",
                    "hint": schema.get("hint") or "",
                    "max_chars": schema.get("max_chars"),
                    "required": bool(schema.get("required", False)),
                }
            )
        else:
            for key, value in schema.items():
                results.extend(_collect_fields(value, prefix + (key,)))
    else:
        # å…¼å®¹æ—§æ ¼å¼ï¼šå­—ç¬¦ä¸²æˆ–å…¶ä»–ç±»å‹è§†ä¸ºæ–‡æœ¬å¶å­
        results.append(
            {
                "path": prefix,
                "is_image": any(
                    "å›¾ç‰‡" in seg or "image" in seg.lower() for seg in prefix
                ),
                "hint": "",
                "max_chars": None,
                "required": False,
            }
        )
    return results


def _clone_schema(schema: Dict) -> Dict:
    return json.loads(json.dumps(schema, ensure_ascii=False))


def _assign_in_schema(schema: Dict, path: List[str], value: str):
    node = schema
    for key in path[:-1]:
        node = node.setdefault(key, {})
    leaf = node.get(path[-1])
    if isinstance(leaf, dict) and "type" in leaf:
        leaf["value"] = value
    else:
        node[path[-1]] = value


def _is_multimodal_llm(llm: Optional[BaseLLM]) -> bool:
    """æ£€æŸ¥æ˜¯å¦ä¸ºå¤šæ¨¡æ€æ¨¡å‹"""
    return isinstance(llm, (TaichuLLM, GLMLLM))


def _simple_fill(template_info: Dict, raw_text: str, images: List[str]) -> Dict:
    result = _clone_schema(template_info["schema"])
    text_fields = template_info["text_fields"]
    image_fields = template_info["image_fields"]
    if text_fields:
        _assign_in_schema(result, list(text_fields[0]["path"]), raw_text)
        for field in text_fields[1:]:
            _assign_in_schema(result, list(field["path"]), "")
    for idx, field in enumerate(image_fields):
        value = images[idx] if idx < len(images) else ""
        _assign_in_schema(result, list(field["path"]), value)
    return result


def _build_prompt(
    template_info: Dict,
    raw_text: str,
    images: List[str],
    is_multimodal: bool = False,
    user_prompt: Optional[str] = None,
) -> str:
    def describe_fields(fields):
        if not fields:
            return "æ— "
        lines = []
        for idx, field in enumerate(fields, 1):
            name = "/".join(field["path"])
            hint = field.get("hint") or "å¡«å†™å†…å®¹"
            extra = []
            if field.get("max_chars"):
                extra.append(f"â‰¤{field['max_chars']}å­—")
            if field.get("required"):
                extra.append("å¿…å¡«")
            extra_note = f"ï¼ˆ{'ï¼Œ'.join(extra)}ï¼‰" if extra else ""
            lines.append(f"{idx}. {name}ï¼š{hint}{extra_note}")
        return "\n".join(lines)

    text_desc = describe_fields(template_info["text_fields"])
    image_desc = describe_fields(template_info["image_fields"])

    # å¯¹äºå¤šæ¨¡æ€æ¨¡å‹ï¼Œä¸éœ€è¦åˆ—å‡ºå›¾ç‰‡è·¯å¾„ï¼ˆå›¾ç‰‡å·²é€šè¿‡ base64 é™„åŠ ï¼‰
    if is_multimodal:
        image_section = f"å·²é™„åŠ  {len(images)} å¼ å›¾ç‰‡ä¾›ä½ å‚è€ƒ"
    else:
        image_section = "æ— " if not images else "\n".join(images)

    meta = template_info.get("meta") or {}
    scene = "ã€".join(meta.get("scene", [])) or "é€šç”¨"
    layout = meta.get("layout", template_info["page_type"])
    style = meta.get("style", "")
    note = meta.get("notes", "")

    multimodal_instruction = ""
    if is_multimodal and images:
        multimodal_instruction = f"""
ğŸ–¼ï¸ å¤šæ¨¡æ€å›¾ç‰‡ç†è§£ï¼ˆé‡è¦ï¼‰ï¼š
æˆ‘å·²é™„å¸¦äº† {len(images)} å¼ å›¾ç‰‡ï¼Œè¿™äº›å›¾ç‰‡æ˜¯è®²ç¨¿çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œè¯·åŠ¡å¿…è®¤çœŸå¤„ç†ã€‚

å›¾ç‰‡ä¸æ–‡æœ¬çš„å…³ç³»ï¼š
- æ¯å¼ å›¾ç‰‡éƒ½ç´§è·Ÿåœ¨ç›¸å…³æ–‡æœ¬æ®µè½çš„ä¸‹æ–¹ï¼ˆå›¾ç‰‡åœ¨æ–‡æœ¬ä¸‹æ–¹ï¼‰
- å›¾ç‰‡æ˜¯å¯¹ä¸Šæ–¹æ–‡æœ¬çš„è¡¥å……è¯´æ˜ã€ç¤ºä¾‹æˆ–å¯è§†åŒ–
- è®²ç¨¿æ–‡æœ¬ä¸­çš„ `[å›¾ç‰‡èµ„æº: ...]` æ ‡è®°ä»…ç”¨äºæŒ‡ç¤ºå›¾ç‰‡åœ¨åŸæ–‡ä¸­çš„ä½ç½®

ä½ çš„ä»»åŠ¡ï¼š
1. ä»”ç»†æŸ¥çœ‹æ¯å¼ å›¾ç‰‡çš„å†…å®¹ï¼Œç†è§£å›¾ç‰‡ä¼ è¾¾çš„ä¿¡æ¯
2. åˆ†æå›¾ç‰‡ä¸ä¸Šä¸‹æ–‡æ–‡æœ¬çš„å…³ç³»ï¼Œç¡®å®šå›¾ç‰‡æ‰€å±çš„ä¸»é¢˜
3. å°†å›¾ç‰‡æ”¾å…¥åˆé€‚çš„å›¾ç‰‡å­—æ®µï¼ˆé€šå¸¸ä¸ç›¸å…³æ–‡æœ¬åœ¨åŒä¸€é¡µ PPTï¼‰
4. åœ¨ JSON çš„ "images" æ•°ç»„å¯¹åº”ä½ç½®å¡«å…¥è¯¥å›¾ç‰‡çš„å®Œæ•´è·¯å¾„
5. æ ¹æ®å›¾ç‰‡å†…å®¹ä¼˜åŒ–æ–‡æœ¬æè¿°ï¼Œä½¿å…¶æ›´å‡†ç¡®ã€æ›´ç”ŸåŠ¨
6. å¦‚æœå›¾ç‰‡å­—æ®µä¸éœ€è¦å›¾ç‰‡ï¼Œè¯·ç•™ç©ºå­—ç¬¦ä¸²

âš ï¸ é‡è¦ï¼šä¸è¦å¿½ç•¥å›¾ç‰‡ï¼å›¾ç‰‡æ˜¯è®²ç¨¿çš„æ ¸å¿ƒå†…å®¹ä¹‹ä¸€ï¼Œå¿…é¡»åˆç†ä½¿ç”¨ã€‚
"""

    prompt = f"""
è¯·é˜…è¯»ä»¥ä¸‹è®²ç¨¿å¹¶ç”Ÿæˆä¸€ä¸ª JSONï¼Œå¯¹æ¨¡æ¿ã€Š{template_info["page_type"]}ã€‹çš„æ–‡æœ¬/å›¾ç‰‡å­—æ®µè¿›è¡Œå¡«å……ã€‚
æ¨¡æ¿å¸ƒå±€ï¼š{layout}ï¼›ä½¿ç”¨åœºæ™¯ï¼š{scene}ï¼›é£æ ¼æç¤ºï¼š{style}
æ³¨æ„äº‹é¡¹ï¼š{note}
{multimodal_instruction}

ğŸ“Œ æ ¸å¿ƒåŸåˆ™ï¼ˆå¹»ç¯ç‰‡ vs è®²ç¨¿ï¼‰ï¼š
è®²ç¨¿æ˜¯æ¼”è®²è€…æ‰‹é‡Œçš„ç¨¿å­ï¼Œæ˜¯ä»–æ¼”è®²æ—¶è¦è¯´çš„å®Œæ•´å†…å®¹ã€‚
å¹»ç¯ç‰‡æ˜¯æŠ•å½±ç»™è§‚ä¼—çœ‹çš„ï¼Œåº”è¯¥æ˜¯è®²ç¨¿çš„**ç²¾ç‚¼è¦ç‚¹**ï¼Œè€Œéç…§æ¬å…¨æ–‡ã€‚
ä½ éœ€è¦æŠŠè®²ç¨¿å†…å®¹**æç‚¼ã€æ¦‚æ‹¬ã€åˆ†ç‚¹**åæ”¾åˆ°å¹»ç¯ç‰‡ä¸Šã€‚

âœ… æ­£ç¡®åšæ³•ï¼š
- æå–æ ¸å¿ƒè§‚ç‚¹ï¼Œç”¨ç®€æ´çš„çŸ­è¯­æˆ–çŸ­å¥è¡¨è¾¾
- ä½¿ç”¨è¦ç‚¹åˆ—è¡¨ï¼ˆå¦‚"1. xxx  2. xxx"æˆ–"â€¢ xxx"ï¼‰
- åˆ é™¤å£è¯­åŒ–è¡¨è¾¾ã€è¿‡æ¸¡è¯­ã€è¯¦ç»†è§£é‡Š
- ä¿ç•™å…³é”®æ•°æ®ã€ä¸“æœ‰åè¯ã€æ ¸å¿ƒç»“è®º

âŒ é”™è¯¯åšæ³•ï¼š
- æŠŠè®²ç¨¿çš„é•¿æ®µè½ç›´æ¥å¤åˆ¶åˆ°å¹»ç¯ç‰‡
- ä¿ç•™"æ¥ä¸‹æ¥æˆ‘ä»¬æ¥çœ‹""æ­£å¦‚å‰é¢æ‰€è¯´"ç­‰å£è¯­
- å†…å®¹è¿‡äºè¯¦ç»†ï¼Œåƒåœ¨è¯»æ–‡ç« 

âš ï¸ ä¸¥æ ¼è¦æ±‚ï¼ˆå¿…é¡»éµå®ˆï¼‰ï¼š
1. æ‰€æœ‰æ ‡è®°ä¸º"required"çš„å­—æ®µå¿…é¡»å¡«å†™ï¼Œç»å¯¹ä¸å¾—ç•™ç©ºã€‚
2. æ¯ä¸ªæ–‡æœ¬å­—æ®µéƒ½æœ‰å­—æ•°ä¸Šé™ï¼ˆmax_charsï¼‰ï¼Œä½ ç”Ÿæˆçš„å†…å®¹ç»å¯¹ä¸èƒ½è¶…è¿‡è¿™ä¸ªé™åˆ¶ã€‚
3. å†…å®¹å¿…é¡»ç²¾ç‚¼ï¼æŠŠè®²ç¨¿çš„å®Œæ•´è¡¨è¿°å‹ç¼©ä¸ºå¹»ç¯ç‰‡è¦ç‚¹ï¼Œåªä¿ç•™æ ¸å¿ƒä¿¡æ¯ã€‚
4. è¿åå­—æ•°é™åˆ¶çš„è¾“å‡ºå°†è¢«è§†ä¸ºæ— æ•ˆï¼Œå¿…é¡»é‡æ–°ç”Ÿæˆã€‚
5. åŠ¡å¿…è®°ä½è®²ç¨¿ä¸­æåˆ°çš„ä¸»è®²äººå§“åã€è¯¾ç¨‹/è®²åº§/é¡¹ç›®åç§°ç­‰å…³é”®ä¸“æœ‰åè¯ï¼Œå¹¶åœ¨æ‰€æœ‰éœ€è¦è¿™äº›ä¿¡æ¯çš„å­—æ®µä¿æŒå®Œå…¨ä¸€è‡´ï¼Œä¸è¦æ”¹å†™ã€‚

è¯¥æ¨¡æ¿åŒ…å«å¦‚ä¸‹æ–‡æœ¬å­—æ®µï¼ˆæŒ‰ç…§é¡ºåºå¯¹åº”ï¼‰ï¼š
{text_desc}

å›¾ç‰‡å­—æ®µï¼ˆè‹¥æ— å¯ç•™ç©ºï¼‰ï¼š
{image_desc}

å¯ç”¨å›¾ç‰‡è·¯å¾„ï¼š
{image_section}

è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
{{
  "texts": ["æ–‡æœ¬1", "æ–‡æœ¬2", "..."],
  "images": ["å›¾ç‰‡è·¯å¾„1", "å›¾ç‰‡è·¯å¾„2", "..."]
}}

è¯·ä¸¥æ ¼ä¿æŒæ•°ç»„é•¿åº¦ä¸å­—æ®µæ•°é‡ä¸€è‡´ï¼Œtexts[1] å¿…é¡»å¯¹åº”ä¸Šè¿°åˆ—è¡¨ä¸­çš„ç¬¬ 1 ä¸ªæ–‡æœ¬å­—æ®µï¼Œä¾æ­¤ç±»æ¨ã€‚
è®²ç¨¿å†…å®¹ï¼š
{raw_text}
"""
    # Append user prompt if provided
    if user_prompt:
        prompt += f"\n\nç”¨æˆ·é¢å¤–è¦æ±‚ï¼š\n{user_prompt}"

    return prompt


def _encode_image(image_path: str) -> Optional[str]:
    """Read image file and return base64 string.

    Returns:
        Base64 encoded string, or None if encoding fails.
    """
    try:
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode("utf-8")
    except FileNotFoundError:
        print(f"âš ï¸ è­¦å‘Šï¼šå›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨ï¼š{image_path}")
        return None
    except Exception as e:
        print(f"âš ï¸ è­¦å‘Šï¼šè¯»å–å›¾ç‰‡å¤±è´¥ {image_path}ï¼š{e}")
        return None


def _build_multimodal_messages(
    template_info: Dict,
    raw_text: str,
    images: List[str],
    user_prompt: Optional[str] = None,
) -> List[Dict]:
    """æ„å»ºå¤šæ¨¡æ€æ¶ˆæ¯ï¼Œç”¨äº Taichu-VL æˆ– GLMVã€‚"""
    prompt_text = _build_prompt(
        template_info, raw_text, images, is_multimodal=True, user_prompt=user_prompt
    )

    content: List[Dict[str, Any]] = [{"type": "text", "text": prompt_text}]

    # æ·»åŠ å›¾ç‰‡
    for img_path in images:
        if not os.path.exists(img_path):
            print(f"âš ï¸ è­¦å‘Šï¼šè·³è¿‡ä¸å­˜åœ¨çš„å›¾ç‰‡ï¼š{img_path}")
            continue

        # Taichu-VL ä½¿ç”¨ OpenAI å…¼å®¹æ ¼å¼ï¼Œæ”¯æŒ data URL (base64)
        # å‚è€ƒï¼šhttps://docs.wair.ac.cn/intelligent/maas/visioIntro.html
        mime_type, _ = mimetypes.guess_type(img_path)
        if not mime_type:
            mime_type = "image/jpeg"

        base64_str = _encode_image(img_path)
        if not base64_str:  # ç¼–ç å¤±è´¥ï¼Œè·³è¿‡æ­¤å›¾ç‰‡
            continue

        data_url = f"data:{mime_type};base64,{base64_str}"

        content.append({"type": "image_url", "image_url": {"url": data_url}})

    return [{"role": "user", "content": content}]


def _lookup_field_value(field, payload, fallback_list, idx):
    path = list(field["path"])
    key = "/".join(path)

    def normalize(text):
        return "".join(ch for ch in text.lower() if ch not in {" ", "_"})

    if isinstance(payload, dict):
        norm_targets = {normalize(key), normalize(path[-1])}
        for candidate_key, candidate_val in payload.items():
            norm = normalize(candidate_key)
            if norm in norm_targets or any(
                target and target in norm for target in norm_targets
            ):
                return candidate_val
        values = list(payload.values())
        if idx < len(values):
            return values[idx]
        return values[-1] if values else ""

    if isinstance(fallback_list, list):
        return fallback_list[idx] if idx < len(fallback_list) else ""
    return ""


def llm_fill_slide(
    llm: BaseLLM,
    template_info: Dict,
    raw_text: str,
    images: List[str],
    user_prompt: Optional[str] = None,
    use_multimodal: bool = True,
) -> Dict:
    """
    ä½¿ç”¨ LLM å¡«å……å•é¡µå¹»ç¯ç‰‡å†…å®¹ã€‚

    Args:
        llm: LLM å®ä¾‹
        template_info: æ¨¡æ¿ä¿¡æ¯
        raw_text: åŸå§‹æ–‡æœ¬
        images: å›¾ç‰‡è·¯å¾„åˆ—è¡¨
        user_prompt: ç”¨æˆ·è‡ªå®šä¹‰ prompt
        use_multimodal: æ˜¯å¦ä½¿ç”¨å¤šæ¨¡æ€æ¶ˆæ¯ï¼ˆé»˜è®¤ Trueï¼‰
                       å½“è®²ç¨¿æœ‰ PPT æ ‡è®°æ—¶ï¼Œå›¾ç‰‡ä½ç½®å·²ç¡®å®šï¼Œå¯è®¾ä¸º False
    """
    if not llm:
        return _simple_fill(template_info, raw_text, images)

    # åªæœ‰åœ¨å…è®¸ä½¿ç”¨å¤šæ¨¡æ€ä¸”æ¨¡å‹æ”¯æŒå¤šæ¨¡æ€ä¸”æœ‰å›¾ç‰‡æ—¶ï¼Œæ‰ä½¿ç”¨å¤šæ¨¡æ€æ¶ˆæ¯
    if use_multimodal and _is_multimodal_llm(llm) and images:
        messages = _build_multimodal_messages(
            template_info, raw_text, images, user_prompt
        )
    else:
        prompt = _build_prompt(template_info, raw_text, images, user_prompt=user_prompt)
        messages = [{"role": "user", "content": prompt}]

    if DEBUG_LLM:
        print(f"\n{'=' * 60}")
        print(f"ğŸ” [DEBUG] LLM è¯·æ±‚ (llm_fill_slide)")
        print(f"{'=' * 60}")
        # æ£€æŸ¥å®é™…å‘é€çš„æ¶ˆæ¯ç±»å‹
        is_multimodal_message = messages and isinstance(
            messages[0].get("content"), list
        )
        if is_multimodal_message:
            print(f"ğŸ“ å¤šæ¨¡æ€æ¶ˆæ¯ (æ–‡æœ¬ + {len(images)} å¼ å›¾ç‰‡)")
            # åªæ‰“å°æ–‡æœ¬éƒ¨åˆ†ï¼Œå›¾ç‰‡å¤ªé•¿ä¸æ‰“å°
            for msg in messages:
                if isinstance(msg.get("content"), list):
                    for item in msg["content"]:
                        if item.get("type") == "text":
                            print(f"æ–‡æœ¬å†…å®¹:\n{item['text'][:500]}...")
        else:
            print(f"ğŸ“ æ–‡æœ¬æ¶ˆæ¯:\n{messages[0]['content'][:500]}...")
        print(f"{'=' * 60}\n")

    response = llm.generate(messages, temperature=0.2)

    if DEBUG_LLM:
        print(f"\n{'=' * 60}")
        print(f"ğŸ“¥ [DEBUG] LLM å“åº” (llm_fill_slide)")
        print(f"{'=' * 60}")
        print(f"{response[:500]}...")
        print(f"{'=' * 60}\n")
    try:
        data = _ensure_json_object(response)
        texts = data.get("texts", [])
        imgs = data.get("images", [])
    except Exception:
        texts, imgs = [raw_text], images

    result = _clone_schema(template_info["schema"])
    text_fields = template_info["text_fields"]
    image_fields = template_info["image_fields"]

    for idx, field in enumerate(text_fields):
        value = _lookup_field_value(
            field, texts, texts if isinstance(texts, list) else None, idx
        )
        _assign_in_schema(result, list(field["path"]), value)

    for idx, field in enumerate(image_fields):
        value = _lookup_field_value(
            field, imgs, imgs if isinstance(imgs, list) else None, idx
        )
        if not value and isinstance(images, list) and idx < len(images):
            value = images[idx]
        _assign_in_schema(result, list(field["path"]), value)

    return result


def llm_plan_slides(
    llm: BaseLLM,
    doc_text: str,
    templates: Dict[int, Dict],
    images: List[str],
    user_prompt: Optional[str] = None,
) -> List[Dict]:
    template_desc = "\n".join(
        f"- æ¨¡æ¿ {info['page_type']} (ç¼–å· {num}): æ–‡æœ¬{len(info['text_fields'])}é¡¹, å›¾ç‰‡{len(info['image_fields'])}é¡¹"
        for num, info in templates.items()
    )

    # å¯¹äºå¤šæ¨¡æ€æ¨¡å‹ï¼Œä¸éœ€è¦åˆ—å‡ºå›¾ç‰‡è·¯å¾„ï¼ˆå›¾ç‰‡å·²é€šè¿‡ base64 é™„åŠ ï¼‰
    if _is_multimodal_llm(llm) and images:
        image_section = f"å·²é™„åŠ  {len(images)} å¼ å›¾ç‰‡ä¾›ä½ å‚è€ƒ"
    else:
        image_section = "æ— " if not images else "\n".join(images)

    multimodal_instruction = ""
    if _is_multimodal_llm(llm) and images:
        multimodal_instruction = f"""
ğŸ–¼ï¸ å¤šæ¨¡æ€å›¾ç‰‡ç†è§£ï¼ˆé‡è¦ï¼‰ï¼š
æˆ‘å·²é™„å¸¦äº† {len(images)} å¼ å›¾ç‰‡ï¼Œè¿™äº›å›¾ç‰‡æ˜¯è®²ç¨¿çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œè¯·åŠ¡å¿…è®¤çœŸå¤„ç†ã€‚

å›¾ç‰‡ä¸æ–‡æœ¬çš„å…³ç³»ï¼š
- æ¯å¼ å›¾ç‰‡éƒ½ç´§è·Ÿåœ¨ç›¸å…³æ–‡æœ¬æ®µè½çš„ä¸‹æ–¹ï¼ˆå›¾ç‰‡åœ¨æ–‡æœ¬ä¸‹æ–¹ï¼‰
- å›¾ç‰‡æ˜¯å¯¹ä¸Šæ–¹æ–‡æœ¬çš„è¡¥å……è¯´æ˜ã€ç¤ºä¾‹æˆ–å¯è§†åŒ–
- è®²ç¨¿æ–‡æœ¬ä¸­çš„ `[å›¾ç‰‡èµ„æº: ...]` æ ‡è®°ä»…ç”¨äºæŒ‡ç¤ºå›¾ç‰‡åœ¨åŸæ–‡ä¸­çš„ä½ç½®

ä½ çš„ä»»åŠ¡ï¼š
1. ä»”ç»†æŸ¥çœ‹æ¯å¼ å›¾ç‰‡çš„å†…å®¹ï¼Œç†è§£å›¾ç‰‡ä¼ è¾¾çš„ä¿¡æ¯
2. åˆ†æå›¾ç‰‡ä¸ä¸Šä¸‹æ–‡æ–‡æœ¬çš„å…³ç³»ï¼Œç¡®å®šå›¾ç‰‡æ‰€å±çš„ä¸»é¢˜
3. å°†å›¾ç‰‡æ”¾å…¥åˆé€‚çš„æ¨¡æ¿çš„å›¾ç‰‡å­—æ®µï¼ˆé€šå¸¸ä¸ç›¸å…³æ–‡æœ¬åœ¨åŒä¸€é¡µ PPTï¼‰
4. åœ¨è¾“å‡ºçš„ JSON å¯¹è±¡ä¸­ï¼Œ"images" æ•°ç»„åº”åŒ…å«ä½ é€‰æ‹©ä½¿ç”¨çš„å›¾ç‰‡å®Œæ•´è·¯å¾„
5. æ ¹æ®å›¾ç‰‡å†…å®¹ä¼˜åŒ–æ–‡æœ¬æè¿°ï¼Œä½¿å…¶æ›´å‡†ç¡®ã€æ›´ç”ŸåŠ¨

âš ï¸ é‡è¦ï¼šä¸è¦å¿½ç•¥å›¾ç‰‡ï¼å›¾ç‰‡æ˜¯è®²ç¨¿çš„æ ¸å¿ƒå†…å®¹ä¹‹ä¸€ï¼Œå¿…é¡»åˆç†ä½¿ç”¨ã€‚
"""

    prompt = f"""
è¯·å°†ä»¥ä¸‹è®²ç¨¿æ‹†åˆ†æˆè‹¥å¹²å¼  PPTï¼Œæ¯å¼ å¹»ç¯ç‰‡é€‰æ‹©ä¸€ä¸ªæ¨¡æ¿ï¼Œå¹¶è¾“å‡º JSON æ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ï¼š
- template_page_num: æ¨¡æ¿ç¼–å·
- page_type: æ¨¡æ¿åç§°
- texts: æŒ‰æ¨¡æ¿æ–‡æœ¬å­—æ®µé¡ºåºç»™å‡ºçš„å†…å®¹æ•°ç»„
- images: æŒ‰æ¨¡æ¿å›¾ç‰‡å­—æ®µé¡ºåºç»™å‡ºçš„å†…å®¹æ•°ç»„

æ¨¡æ¿ä¿¡æ¯ï¼š
{template_desc}

å¯ç”¨å›¾ç‰‡è·¯å¾„ï¼š
{image_section}

{multimodal_instruction}

è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
[
  {{
    "template_page_num": 4,
    "page_type": "ç›®å½•é¡µ",
    "texts": ["ç›®å½•æ ‡é¢˜", "æ¡ç›®1", "æ¡ç›®1è¯´æ˜", "..."],
    "images": [""]
  }},
  ...
]


ğŸ“Œ æ ¸å¿ƒåŸåˆ™ï¼ˆå¹»ç¯ç‰‡ vs è®²ç¨¿ï¼‰ï¼š
è®²ç¨¿æ˜¯æ¼”è®²è€…æ‰‹é‡Œçš„ç¨¿å­ï¼Œæ˜¯ä»–æ¼”è®²æ—¶è¦è¯´çš„å®Œæ•´å†…å®¹ã€‚
å¹»ç¯ç‰‡æ˜¯æŠ•å½±ç»™è§‚ä¼—çœ‹çš„ï¼Œåº”è¯¥æ˜¯è®²ç¨¿çš„**ç²¾ç‚¼è¦ç‚¹**ï¼Œè€Œéç…§æ¬å…¨æ–‡ã€‚
ä½ éœ€è¦æŠŠè®²ç¨¿å†…å®¹**æç‚¼ã€æ¦‚æ‹¬ã€åˆ†ç‚¹**åæ”¾åˆ°å¹»ç¯ç‰‡ä¸Šã€‚

âœ… æ­£ç¡®åšæ³•ï¼š
- æå–æ ¸å¿ƒè§‚ç‚¹ï¼Œç”¨ç®€æ´çš„çŸ­è¯­æˆ–çŸ­å¥è¡¨è¾¾
- ä½¿ç”¨è¦ç‚¹åˆ—è¡¨ï¼ˆå¦‚"1. xxx  2. xxx"æˆ–"â€¢ xxx"ï¼‰
- åˆ é™¤å£è¯­åŒ–è¡¨è¾¾ã€è¿‡æ¸¡è¯­ã€è¯¦ç»†è§£é‡Š
- ä¿ç•™å…³é”®æ•°æ®ã€ä¸“æœ‰åè¯ã€æ ¸å¿ƒç»“è®º

âŒ é”™è¯¯åšæ³•ï¼š
- æŠŠè®²ç¨¿çš„é•¿æ®µè½ç›´æ¥å¤åˆ¶åˆ°å¹»ç¯ç‰‡
- ä¿ç•™"æ¥ä¸‹æ¥æˆ‘ä»¬æ¥çœ‹""æ­£å¦‚å‰é¢æ‰€è¯´"ç­‰å£è¯­
- å†…å®¹è¿‡äºè¯¦ç»†ï¼Œåƒåœ¨è¯»æ–‡ç« 

âš ï¸ ä¸¥æ ¼è¦æ±‚ï¼ˆå¿…é¡»éµå®ˆï¼‰ï¼š
1. æ‰€æœ‰æ ‡è®°ä¸º"required"çš„å­—æ®µå¿…é¡»å¡«å†™ï¼Œç»å¯¹ä¸å¾—ç•™ç©ºã€‚
2. æ¯ä¸ªæ–‡æœ¬å­—æ®µéƒ½æœ‰å­—æ•°ä¸Šé™ï¼ˆmax_charsï¼‰ï¼Œä½ ç”Ÿæˆçš„å†…å®¹ç»å¯¹ä¸èƒ½è¶…è¿‡è¿™ä¸ªé™åˆ¶ã€‚
3. å†…å®¹å¿…é¡»ç²¾ç‚¼ï¼æŠŠè®²ç¨¿çš„å®Œæ•´è¡¨è¿°å‹ç¼©ä¸ºå¹»ç¯ç‰‡è¦ç‚¹ï¼Œåªä¿ç•™æ ¸å¿ƒä¿¡æ¯ã€‚
4. è¿åå­—æ•°é™åˆ¶çš„è¾“å‡ºå°†è¢«è§†ä¸ºæ— æ•ˆï¼Œå¿…é¡»é‡æ–°ç”Ÿæˆã€‚
5. åŠ¡å¿…è®°ä½å¹¶é‡å¤ä½¿ç”¨è®²ç¨¿ä¸­çš„ä¸»è®²äººå§“åã€è¯¾ç¨‹/è®²åº§/é¡¹ç›®åç§°ç­‰å…³é”®ä¸“æœ‰åè¯ï¼Œç¡®ä¿åœ¨æ‰€æœ‰å¹»ç¯ç‰‡ä¸­éœ€è¦å¡«å†™ä¸“æœ‰åè¯çš„ä½ç½®ä¿æŒä¸€è‡´ï¼Œä¸è¦éšæ„æ”¹å†™æˆ–å¦é€ æ–°åç§°ã€‚

è®²ç¨¿å…¨æ–‡ï¼š
{doc_text}
"""
    # Append user prompt if provided
    if user_prompt:
        prompt += f"\n\nç”¨æˆ·é¢å¤–è¦æ±‚ï¼š\n{user_prompt}"

    if _is_multimodal_llm(llm) and images:
        content: List[Dict[str, Any]] = [{"type": "text", "text": prompt}]
        for img_path in images:
            if not os.path.exists(img_path):
                print(f"âš ï¸ è­¦å‘Šï¼šè·³è¿‡ä¸å­˜åœ¨çš„å›¾ç‰‡ï¼š{img_path}")
                continue
            mime_type, _ = mimetypes.guess_type(img_path)
            if not mime_type:
                mime_type = "image/jpeg"
            base64_str = _encode_image(img_path)
            if not base64_str:  # ç¼–ç å¤±è´¥ï¼Œè·³è¿‡æ­¤å›¾ç‰‡
                continue
            data_url = f"data:{mime_type};base64,{base64_str}"
            content.append({"type": "image_url", "image_url": {"url": data_url}})
        messages = [{"role": "user", "content": content}]
    else:
        messages = [{"role": "user", "content": prompt}]

    if DEBUG_LLM:
        print(f"\n{'=' * 60}")
        print("ğŸ” [DEBUG] LLM è¯·æ±‚ (llm_plan_slides)")
        print(f"{'=' * 60}")
        if _is_multimodal_llm(llm) and images:
            print(f"ğŸ“ å¤šæ¨¡æ€æ¶ˆæ¯ (æ–‡æœ¬ + {len(images)} å¼ å›¾ç‰‡)")
            # åªæ‰“å°æ–‡æœ¬éƒ¨åˆ†
            for msg in messages:
                if isinstance(msg.get("content"), list):
                    for item in msg["content"]:
                        if isinstance(item, dict) and item.get("type") == "text":
                            print(f"æ–‡æœ¬å†…å®¹:\n{item['text'][:500]}...")
        else:
            print(f"ğŸ“ æ–‡æœ¬æ¶ˆæ¯:\n{messages[0]['content'][:500]}...")
        print(f"{'=' * 60}\n")

    response = llm.generate(messages, temperature=0.3)

    if DEBUG_LLM:
        print(f"\n{'=' * 60}")
        print("ğŸ“¥ [DEBUG] LLM å“åº” (llm_plan_slides)")
        print(f"{'=' * 60}")
        print(f"{response[:500]}...")
        print(f"{'=' * 60}\n")

    try:
        plan = _ensure_json_array(response)
        return plan
    except Exception:
        raise ValueError("æ¨¡å‹è¾“å‡ºæ— æ³•è§£æä¸º JSON æ•°ç»„ï¼Œè¯·æ£€æŸ¥æç¤ºæˆ–é‡è¯•ã€‚")


def llm_preprocess_script(
    llm: BaseLLM,
    doc_text: str,
    templates: Dict[int, Dict],
    images: List[str],
    user_prompt: Optional[str] = None,
) -> str:
    """
    ä½¿ç”¨ LLM å°†åŸå§‹è®²ç¨¿é¢„å¤„ç†ä¸ºå¸¦ã€PPTã€‘æ ‡è®°çš„ä¸­é—´è®²ç¨¿ã€‚

    Args:
        llm: LLM å®ä¾‹
        doc_text: åŸå§‹è®²ç¨¿æ–‡æœ¬
        templates: æ¨¡æ¿å®šä¹‰å­—å…¸
        images: å›¾ç‰‡è·¯å¾„åˆ—è¡¨
        user_prompt: ç”¨æˆ·è‡ªå®šä¹‰æç¤º

    Returns:
        å¸¦æœ‰ã€PPT1ã€‘ã€PPT2ã€‘ç­‰æ ‡è®°çš„ Markdown æ ¼å¼è®²ç¨¿
    """
    if not llm:
        raise ValueError("é¢„å¤„ç†è®²ç¨¿éœ€è¦å¯ç”¨ LLMã€‚")

    # æ„å»ºæ¨¡æ¿æè¿°
    template_desc_lines = []
    for num, info in templates.items():
        text_count = len(info["text_fields"])
        image_count = len(info["image_fields"])
        page_type = info["page_type"]

        # è·å–æ–‡æœ¬å­—æ®µçš„è¯¦ç»†ä¿¡æ¯
        text_fields_desc = []
        for field in info["text_fields"]:
            name = field.get("name", "æœªå‘½å")
            max_chars = field.get("max_chars", "æ— é™åˆ¶")
            text_fields_desc.append(f"    - {name}ï¼ˆæœ€å¤š{max_chars}å­—ï¼‰")

        image_fields_desc = []
        for field in info["image_fields"]:
            name = field.get("name", "å›¾ç‰‡")
            image_fields_desc.append(f"    - {name}")

        desc = f"ã€PPT{num}ã€‘{page_type}\n  æ–‡æœ¬å­—æ®µ({text_count}ä¸ª):\n"
        desc += "\n".join(text_fields_desc) if text_fields_desc else "    ï¼ˆæ— ï¼‰"
        if image_count > 0:
            desc += f"\n  å›¾ç‰‡å­—æ®µ({image_count}ä¸ª):\n"
            desc += "\n".join(image_fields_desc)
        template_desc_lines.append(desc)

    template_desc = "\n\n".join(template_desc_lines)

    # å›¾ç‰‡ä¿¡æ¯å’Œæ¨¡æ¿é™åˆ¶
    if images:
        image_info = f"è®²ç¨¿ä¸­åŒ…å« {len(images)} å¼ å›¾ç‰‡ï¼Œè¯·åœ¨é€‚å½“ä½ç½®ä¿ç•™å›¾ç‰‡å¼•ç”¨ã€‚"
        # æ‰€æœ‰æ¨¡æ¿éƒ½å¯ç”¨
        available_templates = list(templates.keys())
    else:
        image_info = "âš ï¸ è®²ç¨¿ä¸­ã€æ²¡æœ‰å›¾ç‰‡ã€‘ï¼Œè¯·ã€åªé€‰æ‹©ä¸åŒ…å«å›¾ç‰‡å­—æ®µçš„æ¨¡æ¿ã€‘ï¼"
        # åªä¿ç•™æ²¡æœ‰å›¾ç‰‡å­—æ®µçš„æ¨¡æ¿
        available_templates = [
            num for num, info in templates.items() if len(info["image_fields"]) == 0
        ]
        image_info += f"\nå¯ç”¨æ¨¡æ¿ç¼–å·ï¼š{available_templates}"

    prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ¼”è®²ç¨¿ç¼–è¾‘ã€‚è¯·å°†ä»¥ä¸‹åŸå§‹è®²ç¨¿æ”¹å†™ä¸ºé€‚åˆ PPT æ¼”ç¤ºçš„æ­£å¼æ¼”è®²ç¨¿ã€‚

## ä»»åŠ¡è¯´æ˜

1. **åˆ†æè®²ç¨¿ç»“æ„**ï¼šç†è§£è®²ç¨¿çš„ä¸»é¢˜ã€é€»è¾‘å’Œå†…å®¹å±‚æ¬¡
2. **é€‰æ‹©åˆé€‚æ¨¡æ¿**ï¼šæ ¹æ®å†…å®¹ä¸ºæ¯ä¸ªéƒ¨åˆ†é€‰æ‹©æœ€åˆé€‚çš„ PPT æ¨¡æ¿
3. **æ·»åŠ é¡µç æ ‡è®°**ï¼šåœ¨æ¯ä¸ªéƒ¨åˆ†å¼€å¤´ç”¨ã€PPTç¼–å·ã€‘æ ‡è®°è¯¥éƒ¨åˆ†ä½¿ç”¨çš„æ¨¡æ¿
4. **ä¼˜åŒ–è¡¨è¾¾**ï¼šå°†å†…å®¹æ”¹å†™ä¸ºæ­£å¼ã€ç®€æ´çš„æ¼”è®²é£æ ¼ï¼Œä½†ä¸æ”¹å˜åŸæ„
5. **æ§åˆ¶ç¯‡å¹…**ï¼šæ ¹æ®æ¯ä¸ªæ¨¡æ¿çš„å­—æ•°é™åˆ¶ï¼Œç²¾ç®€å†…å®¹ä½¿å…¶é€‚åˆ PPT å±•ç¤º

## å¯ç”¨æ¨¡æ¿

{template_desc}

## å›¾ç‰‡ä¿¡æ¯

{image_info}

## è¾“å‡ºæ ¼å¼è¦æ±‚

è¾“å‡ºä¸º Markdown æ ¼å¼ï¼Œæ¯ä¸ª PPT é¡µé¢ä»¥ã€PPTç¼–å·ã€‘å¼€å¤´ï¼Œä¾‹å¦‚ï¼š

```
ã€PPT2ã€‘
# è¯¾ç¨‹ä»‹ç»

æœ¬è¯¾ç¨‹å°†å¸¦æ‚¨äº†è§£äººå·¥æ™ºèƒ½çš„åŸºç¡€çŸ¥è¯†...

ã€PPT4ã€‘
# è¯¾ç¨‹ç›®å½•

1. æœºå™¨å­¦ä¹ åŸºç¡€
2. æ·±åº¦å­¦ä¹ å…¥é—¨
3. å®è·µæ¡ˆä¾‹åˆ†æ

ã€PPT5ã€‘
# æœºå™¨å­¦ä¹ åŸºç¡€

æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒæŠ€æœ¯...

[å›¾ç‰‡èµ„æº: doc_image_1.png]
```

## æ³¨æ„äº‹é¡¹

1. æ¯ä¸ªã€PPTç¼–å·ã€‘æ ‡è®°å¿…é¡»ç‹¬å ä¸€è¡Œ
2. ç¼–å·å¿…é¡»æ˜¯ä¸Šé¢æ¨¡æ¿åˆ—è¡¨ä¸­å­˜åœ¨çš„ç¼–å·
3. **é‡è¦**ï¼šå¦‚æœè®²ç¨¿æ²¡æœ‰å›¾ç‰‡ï¼Œåˆ™ã€ç¦æ­¢ã€‘ä½¿ç”¨å¸¦å›¾ç‰‡å­—æ®µçš„æ¨¡æ¿ï¼
4. å†…å®¹è¦ç²¾ç‚¼ï¼Œé€‚åˆ PPT å±•ç¤ºï¼Œé¿å…å¤§æ®µæ–‡å­—
5. ä¿ç•™è®²ç¨¿ä¸­çš„å…³é”®ä¿¡æ¯ã€ä¸“æœ‰åè¯å’Œæ•°æ®
6. å¦‚æœ‰å›¾ç‰‡å¼•ç”¨ï¼ˆ[å›¾ç‰‡èµ„æº: ...]ï¼‰ï¼Œè¯·ä¿ç•™åœ¨åˆé€‚çš„ä½ç½®
7. ä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šè¯´æ˜ï¼Œåªè¾“å‡ºæ”¹å†™åçš„è®²ç¨¿

## åŸå§‹è®²ç¨¿

{doc_text}
"""

    if user_prompt:
        prompt += f"\n\n## ç”¨æˆ·é¢å¤–è¦æ±‚\n\n{user_prompt}"

    # æ„å»ºæ¶ˆæ¯ï¼ˆæ”¯æŒå¤šæ¨¡æ€ï¼‰
    if _is_multimodal_llm(llm) and images:
        content: List[Dict[str, Any]] = [{"type": "text", "text": prompt}]
        for img_path in images:
            if not os.path.exists(img_path):
                continue
            mime_type, _ = mimetypes.guess_type(img_path)
            if not mime_type:
                mime_type = "image/jpeg"
            base64_str = _encode_image(img_path)
            if not base64_str:
                continue
            data_url = f"data:{mime_type};base64,{base64_str}"
            content.append({"type": "image_url", "image_url": {"url": data_url}})
        messages = [{"role": "user", "content": content}]
    else:
        messages = [{"role": "user", "content": prompt}]

    if DEBUG_LLM:
        print(f"\n{'=' * 60}")
        print("ğŸ” [DEBUG] LLM è¯·æ±‚ (llm_preprocess_script)")
        print(f"{'=' * 60}")
        print(f"ğŸ“ é¢„å¤„ç†è®²ç¨¿è¯·æ±‚")
        print(f"{'=' * 60}\n")

    response = llm.generate(messages, temperature=0.3)

    if DEBUG_LLM:
        print(f"\n{'=' * 60}")
        print("ğŸ“¥ [DEBUG] LLM å“åº” (llm_preprocess_script)")
        print(f"{'=' * 60}")
        print(f"{response[:1000]}...")
        print(f"{'=' * 60}\n")

    # æ¸…ç†å“åº”ï¼šç§»é™¤å¯èƒ½çš„ markdown ä»£ç å—æ ‡è®°
    result = response.strip()
    if result.startswith("```"):
        # ç§»é™¤å¼€å¤´çš„ ```markdown æˆ– ```
        lines = result.split("\n")
        if lines[0].startswith("```"):
            lines = lines[1:]
        if lines and lines[-1].strip() == "```":
            lines = lines[:-1]
        result = "\n".join(lines)

    return result


def _parse_preprocessed_script(
    preprocessed_text: str,
    image_dir: Path,
) -> List[Dict]:
    """
    è§£æé¢„å¤„ç†åçš„å¸¦æ ‡è®°è®²ç¨¿ï¼Œè¿”å› blocks åˆ—è¡¨ã€‚

    Args:
        preprocessed_text: å¸¦ã€PPTã€‘æ ‡è®°çš„è®²ç¨¿æ–‡æœ¬
        image_dir: å›¾ç‰‡ç›®å½•

    Returns:
        blocks åˆ—è¡¨ï¼Œæ¯ä¸ª block åŒ…å« template_hint, text, images
    """
    blocks: List[Dict] = []
    current_block: Optional[Dict] = None

    # æŒ‰è¡Œè§£æ
    for line in preprocessed_text.split("\n"):
        marker_match = MARKER_RE.match(line.strip())
        if marker_match:
            # ä¿å­˜ä¹‹å‰çš„ block
            if current_block and current_block.get("text", "").strip():
                blocks.append(current_block)
            # å¼€å§‹æ–°çš„ block
            template_num = int(marker_match.group(1))
            current_block = {
                "template_hint": template_num,
                "text": "",
                "images": [],
            }
        elif current_block is not None:
            # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡å¼•ç”¨
            img_match = re.search(r"\[å›¾ç‰‡èµ„æº:\s*([^\]]+)\]", line)
            if img_match:
                img_name = img_match.group(1).strip()
                img_path = image_dir / img_name
                if img_path.exists():
                    current_block["images"].append(str(img_path))
                # ä»æ–‡æœ¬ä¸­ç§»é™¤å›¾ç‰‡æ ‡è®°
                line = re.sub(r"\[å›¾ç‰‡èµ„æº:\s*[^\]]+\]", "", line)

            current_block["text"] += line + "\n"

    # ä¿å­˜æœ€åä¸€ä¸ª block
    if current_block and current_block.get("text", "").strip():
        blocks.append(current_block)

    # æ¸…ç†æ¯ä¸ª block çš„æ–‡æœ¬
    for block in blocks:
        block["text"] = block["text"].strip()

    return blocks


def _extract_json_value(text: str, opener: str) -> Any:
    decoder = json.JSONDecoder()
    idx = 0
    while idx < len(text):
        start = text.find(opener, idx)
        if start == -1:
            break
        try:
            value, offset = decoder.raw_decode(text[start:])
            return value
        except json.JSONDecodeError:
            idx = start + 1
    raise ValueError("æ¨¡å‹è¾“å‡ºä¸­æœªæ‰¾åˆ° JSON")


def _ensure_json_object(text: str) -> Dict:
    value = _extract_json_value(text.strip(), "{")
    if not isinstance(value, dict):
        raise ValueError("è§£æç»“æœä¸æ˜¯ JSON å¯¹è±¡")
    return value


def _ensure_json_array(text: str) -> List[Dict]:
    value = _extract_json_value(text.strip(), "[")
    if not isinstance(value, list):
        raise ValueError("è§£æç»“æœä¸æ˜¯ JSON æ•°ç»„")
    return value


def _coerce_dict(entry):
    if isinstance(entry, dict):
        return entry
    if isinstance(entry, str):
        entry = entry.strip()
        if not entry:
            raise ValueError("æ¨¡å‹è¾“å‡ºçš„å…ƒç´ ä¸ºç©ºå­—ç¬¦ä¸²ï¼Œæ— æ³•è§£æä¸º JSON å¯¹è±¡ã€‚")
        if entry.startswith("{"):
            try:
                return json.loads(entry)
            except json.JSONDecodeError as exc:
                raise ValueError("æ¨¡å‹è¾“å‡ºçš„å­—ç¬¦ä¸²ä¸æ˜¯åˆæ³• JSON å¯¹è±¡ã€‚") from exc
        raise ValueError("å­—ç¬¦ä¸²å…ƒç´ å¿…é¡»æ˜¯ JSON å¯¹è±¡å­—é¢é‡ã€‚")
    if isinstance(entry, list):
        for candidate in entry:
            try:
                return _coerce_dict(candidate)
            except ValueError:
                continue
        raise ValueError("åˆ—è¡¨å…ƒç´ ä¸­æœªæ‰¾åˆ° JSON å¯¹è±¡ã€‚")
    raise ValueError("æ¨¡å‹è¾“å‡ºçš„å…ƒç´ ä¸æ˜¯æœ‰æ•ˆçš„ JSON å¯¹è±¡ã€‚")


def choose_llm(
    enable: bool,
    provider: str,
    model: Optional[str],
    base_url: Optional[str] = None,
) -> Optional[BaseLLM]:
    if not enable:
        return None
    provider = (provider or "").lower()

    if provider == "deepseek":
        return DeepSeekLLM(model=model or "deepseek-chat")
    if provider == "local":
        return LocalLLM(model=model)
    if provider == "qwen":
        endpoint = base_url or os.getenv("QWEN_VLLM_BASE_URL")
        if not endpoint:
            raise ValueError(
                "Qwen provider éœ€è¦æä¾› --llm-base-url æˆ–è®¾ç½® QWEN_VLLM_BASE_URLã€‚"
            )
        return QwenVLLM(base_url=endpoint)
    if provider == "taichu":
        final_model = model or "taichu4_vl_32b"
        return TaichuLLM(model=final_model, base_url=base_url)
    if provider == "glm" or provider == "zhipu":
        final_model = model or "glm-4.5v"
        return GLMLLM(model=final_model, base_url=base_url)
    raise ValueError(f"æš‚ä¸æ”¯æŒçš„å¤§æ¨¡å‹æä¾›å•†ï¼š{provider}")


def _apply_metadata_overrides(content: Dict, template_info: Dict, metadata: Dict):
    if not metadata:
        return
    for field in template_info["text_fields"]:
        path = list(field["path"])
        key = "/".join(path)
        value = None
        if metadata.get("lecturer") and "ä¸»è®²" in key:
            value = metadata["lecturer"]
        elif metadata.get("college") and "å­¦é™¢" in key:
            value = metadata["college"]
        elif metadata.get("course") and any(
            token in key for token in ("è¯¾ç¨‹", "è¯¾ç¨‹åç§°", "é¡¹ç›®")
        ):
            value = metadata["course"]
        if value is not None:
            _assign_in_schema(content, path, value)


def _fill_with_template(
    template_num: int,
    template_info: Dict,
    block: Dict,
    llm: Optional[BaseLLM],
    metadata: Dict,
    user_prompt: Optional[str] = None,
    use_multimodal: bool = True,
) -> Dict:
    """
    ä½¿ç”¨æ¨¡æ¿å¡«å……å•ä¸ª block çš„å†…å®¹ã€‚

    Args:
        use_multimodal: æ˜¯å¦ä½¿ç”¨å¤šæ¨¡æ€æ¶ˆæ¯ï¼ˆé»˜è®¤ Trueï¼‰
                       å½“è®²ç¨¿æœ‰ PPT æ ‡è®°æ—¶ï¼Œå›¾ç‰‡ä½ç½®å·²ç¡®å®šï¼Œå»ºè®®è®¾ä¸º False
    """
    content = llm_fill_slide(
        llm,
        template_info,
        block.get("text", ""),
        block.get("images", []),
        user_prompt,
        use_multimodal,
    )
    _apply_metadata_overrides(content, template_info, metadata)
    return {
        "page_type": template_info["page_type"],
        "template_page_num": template_num,
        "content": content,
    }


def _strip_values(node):
    if isinstance(node, dict):
        if "type" in node and "value" in node:
            return node.get("value", "")
        return {k: _strip_values(v) for k, v in node.items()}
    if isinstance(node, list):
        return [_strip_values(item) for item in node]
    return node


def _empty_content(template_info: Dict) -> Dict:
    result = _clone_schema(template_info["schema"])
    for field in template_info["text_fields"]:
        _assign_in_schema(result, list(field["path"]), "")
    for field in template_info["image_fields"]:
        _assign_in_schema(result, list(field["path"]), "")
    return result


def _prepend_cover_page(pages: List[Dict], templates: Dict[int, Dict]):
    cover_template = templates.get(1)
    if not cover_template:
        return
    if pages and pages[0].get("template_page_num") == 1:
        return
    pages.insert(
        0,
        {
            "page_type": cover_template["page_type"],
            "template_page_num": 1,
            "content": _empty_content(cover_template),
        },
    )


def _fill_by_markers(
    blocks: List[Dict],
    templates: Dict[int, Dict],
    llm: Optional[BaseLLM],
    metadata: Dict,
    user_prompt: Optional[str] = None,
) -> List[Dict]:
    """
    æŒ‰ç…§è®²ç¨¿ä¸­çš„ PPT æ ‡è®°å¡«å……å†…å®¹ã€‚

    ç”±äºè®²ç¨¿å·²æœ‰æ˜ç¡®çš„æ ‡è®°ï¼Œå›¾ç‰‡ä½ç½®å·²ç»ç¡®å®šï¼ˆæ¯ä¸ª block çš„ images å­—æ®µï¼‰ï¼Œ
    å› æ­¤ä¸éœ€è¦ä½¿ç”¨å¤šæ¨¡æ€æ¨¡å‹æ¥ç•Œå®šå›¾ç‰‡ä½ç½®ï¼Œè®¾ç½® use_multimodal=Falseã€‚
    """
    pages: List[Dict] = []
    for block in blocks:
        template_num = block.get("template_hint")
        if template_num is None:
            continue
        if template_num not in templates:
            raise ValueError(
                f"æ¨¡æ¿ {template_num} æœªåœ¨ template.json ä¸­å®šä¹‰æˆ–ä¸åœ¨ template.txt ä¸­å…è®¸ã€‚"
            )
        pages.append(
            _fill_with_template(
                template_num,
                templates[template_num],
                block,
                llm,
                metadata,
                user_prompt,
                use_multimodal=False,  # æœ‰æ ‡è®°æ—¶å›¾ç‰‡ä½ç½®å·²ç¡®å®šï¼Œä¸éœ€è¦å¤šæ¨¡æ€
            )
        )
    return pages


def _plan_without_markers(
    blocks: List[Dict],
    templates: Dict[int, Dict],
    llm: BaseLLM,
    metadata: Dict,
    user_prompt: Optional[str] = None,
    run_dir: Optional[Path] = None,
) -> List[Dict]:
    """
    å¤„ç†æ²¡æœ‰ã€PPTã€‘æ ‡è®°çš„è®²ç¨¿ã€‚

    æ–°æµç¨‹ï¼ˆä¸¤æ­¥å¤„ç†ï¼‰ï¼š
    1. é¢„åˆ†é¡µï¼šè®© LLM å°†åŸå§‹è®²ç¨¿æ”¹å†™ä¸ºå¸¦ã€PPTã€‘æ ‡è®°çš„ä¸­é—´è®²ç¨¿
    2. å¡«å……ï¼šå¤ç”¨ _fill_by_markers å¤„ç†ä¸­é—´è®²ç¨¿

    Args:
        blocks: åŸå§‹è®²ç¨¿çš„ block åˆ—è¡¨
        templates: æ¨¡æ¿å®šä¹‰å­—å…¸
        llm: LLM å®ä¾‹
        metadata: å…ƒæ•°æ®
        user_prompt: ç”¨æˆ·è‡ªå®šä¹‰æç¤º
        run_dir: è¿è¡Œç›®å½•ï¼Œç”¨äºä¿å­˜ä¸­é—´è®²ç¨¿

    Returns:
        å¡«å……åçš„é¡µé¢åˆ—è¡¨
    """
    if not llm:
        raise ValueError("è®²ç¨¿æœªæŒ‡å®š PPT æ ‡è®°ä¸”æœªå¯ç”¨ LLMï¼Œæ— æ³•è‡ªåŠ¨åˆ†é…æ¨¡æ¿ã€‚")

    # åˆå¹¶æ‰€æœ‰ block çš„æ–‡æœ¬å’Œå›¾ç‰‡
    doc_text = "\n\n".join(
        block.get("text", "") for block in blocks if block.get("text")
    )
    all_images = [path for block in blocks for path in block.get("images", [])]

    # Step 1: é¢„åˆ†é¡µ - ç”Ÿæˆå¸¦ã€PPTã€‘æ ‡è®°çš„ä¸­é—´è®²ç¨¿
    print("ğŸ“ Step 1: é¢„å¤„ç†è®²ç¨¿ï¼ˆç”Ÿæˆå¸¦æ ‡è®°çš„ä¸­é—´è®²ç¨¿ï¼‰...")
    preprocessed_script = llm_preprocess_script(
        llm, doc_text, templates, all_images, user_prompt
    )

    # ä¿å­˜ä¸­é—´è®²ç¨¿åˆ°æ–‡ä»¶ï¼ˆä¾›ç®¡ç†å‘˜/å¼€å‘è€…ä¸‹è½½ï¼‰
    if run_dir:
        script_path = run_dir / "preprocessed_script.md"
        script_path.write_text(preprocessed_script, encoding="utf-8")
        print(f"ğŸ’¾ ä¸­é—´è®²ç¨¿å·²ä¿å­˜: {script_path}")

    # Step 2: è§£æä¸­é—´è®²ç¨¿ä¸º blocks
    image_dir = run_dir / "images" if run_dir else Path(".")
    preprocessed_blocks = _parse_preprocessed_script(preprocessed_script, image_dir)

    if not preprocessed_blocks:
        raise ValueError("é¢„å¤„ç†åçš„è®²ç¨¿æ²¡æœ‰æœ‰æ•ˆçš„ã€PPTã€‘æ ‡è®°ï¼Œè¯·æ£€æŸ¥ LLM è¾“å‡ºã€‚")

    print(f"âœ… é¢„å¤„ç†å®Œæˆï¼Œå…± {len(preprocessed_blocks)} ä¸ªé¡µé¢")

    # Step 3: å¤ç”¨ _fill_by_markers å¤„ç†
    print("ğŸ“ Step 2: å¡«å……é¡µé¢å†…å®¹...")
    pages = _fill_by_markers(preprocessed_blocks, templates, llm, metadata, user_prompt)

    return pages


def generate_config_data(
    docx_path: str,
    template_json: str,
    template_list: str,
    use_llm: bool,
    llm_provider: str,
    llm_model: Optional[str],
    llm_base_url: Optional[str],
    metadata_overrides: Optional[Dict[str, str]],
    run_dir: Path,
    user_prompt: Optional[str] = None,
) -> Dict:
    """æ ¸å¿ƒé€»è¾‘ï¼šç”Ÿæˆ JSON å†…å®¹ï¼Œä¾› GUI/CLI å¤ç”¨ã€‚"""
    metadata_overrides = metadata_overrides or {}
    image_dir = run_dir / "images"
    blocks, has_marker, metadata = parse_docx_blocks(docx_path, image_dir)
    for key in ("course", "college", "lecturer"):
        if metadata_overrides.get(key):
            metadata[key] = metadata_overrides[key]

    templates = load_template_defs(template_json, template_list)
    llm = choose_llm(use_llm, llm_provider, llm_model, llm_base_url)

    if has_marker:
        pages = _fill_by_markers(blocks, templates, llm, metadata, user_prompt)
    else:
        pages = _plan_without_markers(
            blocks, templates, llm, metadata, user_prompt, run_dir
        )

    if not pages:
        raise ValueError("æœªç”Ÿæˆä»»ä½•å¹»ç¯ç‰‡å†…å®¹ï¼Œè¯·æ£€æŸ¥è®²ç¨¿æˆ–æ¨¡æ¿ã€‚")

    _prepend_cover_page(pages, templates)

    stripped_pages = []
    for page in pages:
        stripped_pages.append(
            {
                "page_type": page.get("page_type"),
                "template_page_num": page.get("template_page_num"),
                "content": _strip_values(page.get("content", {})),
            }
        )

    return {"ppt_pages": stripped_pages}


def process_docx(
    docx_path: str,
    template_json: str,
    template_list: str,
    output_path: Optional[str],
    use_llm: bool,
    llm_provider: str,
    llm_model: Optional[str],
    llm_base_url: Optional[str],
    override_course: Optional[str],
    override_college: Optional[str],
    override_lecturer: Optional[str],
    run_dir: Optional[str],
    config_name: str,
):
    """CLI åŒ…è£…ï¼šå¤„ç†å‚æ•°ã€ä¿è¯ run ç›®å½•å­˜åœ¨ï¼Œå¹¶é¢å¤–å¤åˆ¶æ–‡ä»¶åˆ° outputã€‚"""
    metadata_overrides = {
        "course": override_course,
        "college": override_college,
        "lecturer": override_lecturer,
    }

    base_dir = Path(run_dir) if run_dir else _create_run_dir()
    base_dir.mkdir(parents=True, exist_ok=True)
    config_path = base_dir / config_name

    config = generate_config_data(
        docx_path,
        template_json,
        template_list,
        use_llm,
        llm_provider,
        llm_model,
        llm_base_url,
        metadata_overrides,
        base_dir,
    )

    config_path.write_text(
        json.dumps(config, ensure_ascii=False, indent=2), encoding="utf-8"
    )

    if output_path:
        explicit = Path(output_path)
        explicit.parent.mkdir(parents=True, exist_ok=True)
        shutil.copyfile(config_path, explicit)
        print(f"ğŸ“„ å¦å­˜ä¸ºï¼š{explicit}")

    print(f"âœ… å·²ç”Ÿæˆ JSONï¼š{config_path}")
    print(f"ğŸ“ èµ„æºè¾“å‡ºç›®å½•ï¼š{base_dir}")


def build_arg_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(description="æ ¹æ® DOCX è®²ç¨¿ç”Ÿæˆ PPT é…ç½® JSONã€‚")
    parser.add_argument("--docx", required=True, help="è®²ç¨¿ DOCX è·¯å¾„")
    parser.add_argument(
        "--template-json", default="template/template.json", help="æ¨¡æ¿å®šä¹‰ JSON æ–‡ä»¶"
    )
    parser.add_argument(
        "--template-list", default="template/template.txt", help="å¯ç”¨æ¨¡æ¿ç¼–å·åˆ—è¡¨ txt"
    )
    parser.add_argument(
        "--output",
        default=None,
        help="å¦‚éœ€é¢å¤–å¤åˆ¶ä¸€ä»½ JSONï¼Œè¯·æä¾›å®Œæ•´è·¯å¾„ï¼›è‹¥çœç•¥åˆ™ä»…åœ¨ temp/run-*/ ä¸­ç”Ÿæˆ",
    )
    parser.add_argument("--use-llm", action="store_true", help="å¯ç”¨å¤§æ¨¡å‹å¡«å……/æ’ç‰ˆ")
    parser.add_argument("--llm-provider", default="deepseek", help="å¤§æ¨¡å‹æä¾›å•†")
    parser.add_argument("--llm-model", default="deepseek-chat", help="å¤§æ¨¡å‹åç§°")
    parser.add_argument(
        "--llm-base-url",
        default="http://172.18.75.58:9000",
        help="è‡ªå®šä¹‰å¤§æ¨¡å‹æ¥å£åœ°å€",
    )
    parser.add_argument("--course-name", default=None, help="æ‰‹åŠ¨æŒ‡å®šè¯¾ç¨‹/é¡¹ç›®åç§°")
    parser.add_argument("--college-name", default=None, help="æ‰‹åŠ¨æŒ‡å®šå­¦é™¢/å•ä½")
    parser.add_argument("--lecturer-name", default=None, help="æ‰‹åŠ¨æŒ‡å®šä¸»è®²æ•™å¸ˆå§“å")
    parser.add_argument(
        "--run-dir",
        default=None,
        help="æŒ‡å®šè¾“å‡ºç›®å½•ï¼ˆé»˜è®¤åœ¨ temp ä¸‹è‡ªåŠ¨åˆ›å»º run-æ—¶é—´æˆ³-éšæœºå€¼ æ–‡ä»¶å¤¹ï¼‰",
    )
    parser.add_argument(
        "--config-name",
        default="config.json",
        help="è¾“å‡ºç›®å½•ä¸­ç”Ÿæˆçš„é…ç½®æ–‡ä»¶åç§°",
    )
    return parser


def main():
    args = build_arg_parser().parse_args()
    process_docx(
        docx_path=args.docx,
        template_json=args.template_json,
        template_list=args.template_list,
        output_path=args.output,
        use_llm=args.use_llm,
        llm_provider=args.llm_provider,
        llm_model=args.llm_model,
        llm_base_url=args.llm_base_url,
        override_course=args.course_name,
        override_college=args.college_name,
        override_lecturer=args.lecturer_name,
        run_dir=args.run_dir,
        config_name=args.config_name,
    )


def _strip_values(node):
    if isinstance(node, dict):
        if "type" in node and "value" in node:
            return node.get("value", "")
        return {k: _strip_values(v) for k, v in node.items()}
    if isinstance(node, list):
        return [_strip_values(item) for item in node]
    return node


if __name__ == "__main__":
    main()
